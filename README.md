<div dir="rtl">

<div align="center">
<img src="images/poster.jpg" alt="LLM for Humans Poster">
</div>

<div align="center">

# این ریپو همیشه در حال آپدیت شدنه؛ اگه دوست دارید از تغییرات باخبر بشید، دکمه Watch رو بزنید!

</div>

<br>

<div align="center">

# مقدمه 📚

</div>

حدود دو سال پیش حس کردم منابع فارسی زیادی برای یادگیری دیزاین پترن‌ها وجود نداره. برای همین یه ریپو ساختم به اسم [دیزاین پترن به زبان آدمیزاد](https://github.com/3lf/design-patterns-for-humans) که خداروشکر استقبال خوبی هم ازش شد.

حالا با رشد LLMها و تاثیر زیادی که روی کارهای مختلف گذاشتن، فکر کردم وقتش رسیده یه ریپوی دیگه درست کنم تا روش‌های استفاده از این مدل‌های زبانی رو ساده و روشن توضیح بدم. از نحوه‌ی نوشتن پرامپت گرفته تا کلی نکته و ترفند جذاب که میتونه حسابی بهتون کمک کنه.

---

<div align="center">

# مدل‌های زبانی بزرگ (LLM) 🤖

</div>

مدل‌های زبانی بزرگ، که بهشون **LLM** (مخفف **Large Language Model**) گفته می‌شه، سیستم‌های هوشمندی هستن که با حجم زیادی از داده‌ها آموزش دیدن تا بتونن متن، تصویر و صدا رو پردازش کنن، بفهمن و تولید کنن.

**چی کار می‌تونن بکنن؟**  
این مدل‌ها می‌تونن:
- متن بنویسن و خلاصه کنن ✅  
- به سوالات جواب بدن ✅  
- ترجمه کنن ✅  
- گفتگو کنن ✅  
- تحلیل داده انجام بدن ✅  
- کدنویسی کنن ✅  
- و حتی تصویر و صدا بسازن! ✅  

به طور خلاصه، **LLM یه مدل هوشمنده که می‌تونه اطلاعات رو پردازش کنه و خروجی متناسب تولید کنه**.  

هرچقدر ورودی (پرامپت) دقیق‌تر باشه، خروجی هم بهتر می‌شه. برای همین، اگه بخوای نتیجه‌ی خوبی بگیری، باید **پرامپت‌نویسی** بلد باشی و بدونی چطور درخواستت رو به مدل بگی.  
<br>

---

<br>

<div align="center">

# پرامپت‌نویسی ✍️

</div>

پرامپت همون متنیه که شما به یه **LLM** می‌دین تا بر اساسش خروجی تولید کنه. این متن می‌تونه یه سؤال، دستور، توضیح یا هر نوع درخواست دیگه باشه که مدل باید بهش پاسخ بده. **هرچی پرامپت واضح‌تر و دقیق‌تر باشه، جواب بهتری هم می‌گیرین.**  

---

<div align="center">

## چطور یه پرامپت خوب بنویسیم؟ 🏗

</div>

برای گرفتن یه **پاسخ دقیق و کاربردی**، بهتره پرامپت شما این ویژگی‌ها رو داشته باشه:  

✅ **مشخص و شفاف باشه** (از کلی‌گویی پرهیز کن)  
✅ **زمینه و محدودیت‌ها رو مشخص کنه** (مثل لحن، فرمت خروجی یا طول جواب)  
✅ **مثال یا جزئیات بیشتری داشته باشه** (برای درک بهتر مدل)  
✅ **از جملات ساده و مستقیم استفاده کن تا مدل گیج نشه**  

---

<div align="center">

## نمونه‌ای از یک پرامپت خوب 🌍

</div>

### 🎯 مثال: نوشتن یه ایمیل رسمی برای درخواست مرخصی  

**📝 پرامپت:**  
«یه ایمیل رسمی برای درخواست مرخصی سه روزه بنویس که دلیل مرخصی رو هم توضیح بده. ایمیل مودبانه و حرفه‌ای باشه.»  

**💡 جواب LLM:**  

```
موضوع: درخواست مرخصی  

سلام [نام مدیر] عزیز،  
امیدوارم حالتون خوب باشه. من قصد دارم از تاریخ [تاریخ شروع] تا [تاریخ پایان] به دلیل [دلیل مرخصی] مرخصی بگیرم.  
ممنون می‌شم اگه درخواست من رو بررسی کنین و اطلاع بدین.  

با احترام،  
[نام شما]
```

<br>

---

<br>

<div align="center">

# چطور یه پرامپت قوی‌تر بنویسیم؟ 🚀

</div>

وقتی با یه **LLM** کار می‌کنیم، **وضوح** و **دقت** پرامپت خیلی مهمه. توی این متن، چند نکته‌ی کلیدی آورده شده که می‌تونه بهت کمک کنه **جواب‌های بهتر** و **دقیق‌تری** بگیری.

---

<br>

<div align="center">

## 1. استفاده از مرزها برای تفکیک داده‌ها از پرامپت ✂️

</div>

گاهی لازمه **داده‌ها و دستورات** رو از هم جدا کنیم تا مدل بهتر متوجه بشه. روش‌های مختلفی وجود داره:

**الف) استفاده از بلاک‌کد (` ``` `) برای مشخص کردن داده‌ها**  
````markdown
لطفاً یک بیوگرافی کوتاه برای این شخص بنویس:

```
اسم: Ali
سن: 25
```
````

**ب) استفاده از تگ‌های HTML**  
```html
لطفاً یک بیوگرافی کوتاه برای این شخص بنویس:
<data>
    اسم: Ali
    سن: 25
</data>
```


**چرا مهمه؟**  
- مدل می‌فهمه کدوم بخش «داده» و کدوم بخش «درخواست» یا «دستور»ه.  
- باعث می‌شه جواب دقیق‌تر و منسجم‌تری بگیری.

---

<br>

<div align="center">

## 2. درخواست خروجی ساختاریافته 🗂️

</div>

وقتی می‌خوای جواب مدل رو بعداً پردازش کنی یا به فرمی مشخص نیاز داری، **ساختار خروجی** رو دقیق تعیین کن.  

**مثال: دریافت JSON**  
````markdown
لطفاً اطلاعات زیر رو به صورت JSON با کلیدهای `name` و `age` خروجی بده:

```
اسم: Ali
سن: 25
```
````

**پاسخ احتمالی مدل:**  
<div dir="ltr">

```json
{
  "name": "Ali",
  "age": 25
}
```
</div>

**چرا مفیده؟**  
- خروجی **یکنواخت و استاندارد** داری.  
- داده‌ها رو می‌تونی راحت توی برنامه، دیتابیس یا هر جای دیگه پردازش کنی.

---

<br>

<div align="center">

## 3. اضافه کردن اطلاعات سبک برای تغییر لحن خروجی 🎨

</div>

اگه مدل باید **با لحن خاصی** جواب بده—مثلاً دوستانه، رسمی یا طنزآمیز—حتماً توی پرامپت ذکر کن.  

**مثال:**  
```
با لحنی ساده و دوستانه توضیح بده که چطور یه کیک شکلاتی درست کنیم.
```

**نتیجه؟**  
- مدل از کلماتی استفاده می‌کنه که **حس و حال دوستانه** رو منتقل می‌کنن.  
- می‌تونی حتی بگی «مثل یه سرآشپز حرفه‌ای توضیح بده» یا «مثل یه معلم مدرسه بیان کن».  

---

<br>

<div align="center">

## 4. دادن شرایط به مدل و درخواست بررسی آن‌ها ✅

</div>

اگه نیاز داری مدل **چک کنه که فلان شرط درسته یا نه**، حتماً توی پرامپت این شرط‌ها رو روشن کن.  

**مثال:**  
```
اگر سن کاربر بالای ۱۸ سال است و کاربر دارای گواهینامه رانندگی است، لطفاً بنویس که او مجاز به رانندگی است.

سن: ۲۵
گواهینامه: بله
```

**جواب:**  
```
بله، کاربر مجاز به رانندگی است.
```

**فواید؟**  
- مدل **منطق ساده** رو به‌خوبی اجرا می‌کنه.  
- خروجی بهتر و هدفمندتر می‌شه.

---

<br>

<div align="center">

## 5. دادن مثال‌های موفق از انجام وظایف و سپس درخواست 🚀

</div>

اگه مدل **الگوی چند جواب خوب** رو ببینه، می‌تونه **بهتر** از عهده‌ی وظیفه بربیاد. این روش رو مخصوصاً توی مسائل محاسباتی یا طبقه‌بندی امتحان کن.

**مثال:**  
```
مثال:
ورودی: ۵ + ۳
خروجی: ۸

ورودی: ۱۲ - ۴
خروجی: ۸

لطفاً ۷ * ۲ رو محاسبه کن.
```
- مدل می‌بینه که چطور ورودی و خروجی رو تطبیق دادی و **جواب به‌همین شکل** می‌ده.

---

<br>

<div align="center">

## 6. درخواست از مدل برای حل مسئله قبل از دادن جواب 🧩

</div>

گاهی می‌خوای بدونی **فرآیند حل** چیه، نه صرفاً جواب نهایی. از مدل بخواه اول مسئله رو **مرحله‌به‌مرحله** حل کنه.

**مثال:**  
```
لطفاً ابتدا مسئله زیر رو قدم‌به‌قدم حل کن و سپس جواب نهایی رو بنویس:
۳ + ۵ * ۲ - ۸ / ۴ = ؟
```

**چرا خوبه؟**  
- اگه مدل اشتباه کنه، می‌تونی **از روی مراحل بفهمی** مشکل کجاست.  
- گاهی هم می‌خوای خروجی نهایی رو به شکل کاملاً مستدل تحویل بگیری.

---

<br>

<div align="center">

## 7. تکرار و بهبود پرامپت‌ها 🔄

</div>

حتی **بهترین پرامپت‌ها** هم ممکنه **بار اول** نتیجه ایدئال ندن. پس:

1. **پرامپت اولیه** رو بنویس و امتحان کن.  
2. **جواب رو بررسی کن:**  
   - اگه ناقصه یا گیج‌کننده، پرامپت رو واضح‌تر کن.  
   - اگه زیادی تخصصی شده، لحنش رو ساده کن.  
3. **چند بار تست و تغییرش بده** تا مدل بهترین جواب رو بده.

---

<br>

<div align="center">

### جمع‌بندی نهایی ✨

</div>

با رعایت این نکات، می‌تونی پرامپت‌هایی بسازی که **مدل رو به بهترین نحو هدایت** کنه و جواب‌های **دقیق، مرتبط و قابل‌استفاده** بگیری:

- **مرزبندی داده‌ها** (مثل بلاک‌کد و نشانه‌های واضح)  
- **درخواست خروجی ساختاریافته** (JSON یا HTML)  
- **تعیین لحن و سبک** (دوستانه، رسمی و غیره)  
- **ارائه شرایط** برای جواب‌های مشروط  
- **دادن مثال‌های موفق** پیش از درخواست اصلی  
- **درخواست حل مرحله‌به‌مرحله** برای شفافیت در جواب  
- **تست و تکرار** برای بهبود پرامپت‌ها  


<br>

---

<br>

<div align="center">

# پارامترهای مهم در کار با LLMها ⚙️

</div>

**نکته‌ی مهم:** اگه فقط با چت‌بات‌های معمولی مثل ChatGPT یا Gemini کار می‌کنی، احتمالاً نیازی به دستکاری این پارامترها نداری یا اصلاً بهشون دسترسی نداری. ولی دونستن‌شون کمک می‌کنه بفهمی پشت صحنه چه خبره.
**اما:** اگه برنامه‌نویسی می‌کنی و از **API** مدل‌ها استفاده می‌کنی، یا می‌خوای خروجی‌های خیلی خاصی بگیری (مثلاً برای تولید محتوای خلاقانه، کدنویسی دقیق، یا تحلیل داده)، این پارامترها مثل **دکمه‌های تنظیم** جادویی هستن! باهاشون می‌تونی رفتار مدل رو کنترل کنی.

---

<div align="center">

### ۱. Temperature (دمای خلاقیت) 🌡️

</div>

- **چی هست؟** مثل یه **ولوم خلاقیت** برای مدل می‌مونه. تعیین می‌کنه چقدر جواب‌هاش قابل پیش‌بینی یا خلاقانه باشه.

- **عدد کم (مثلاً `0.1` یا `0.2`)**:
    - مدل **محافظه‌کار** می‌شه و جواب‌های **معمول و قابل پیش‌بینی** می‌ده. انگار داره از روی یه متن خیلی خشک می‌خونه.
    - **مناسب برای:** کارهای دقیق مثل خلاصه‌نویسی یه متن علمی، جواب دادن به سوالات با جواب مشخص، یا تولید کد وقتی دقیقاً می‌دونی چی می‌خوای.

- **عدد زیاد (مثلاً `0.8` یا `0.9`)**:
    - مدل **جسور و خلاق** می‌شه! جواب‌های **غیرمنتظره، متنوع و جدید** می‌ده. انگار یه نویسنده خلاق داره برات می‌نویسه.
    - **مناسب برای:** کارهای خلاقانه مثل نوشتن داستان، شعر، ایده‌پردازی، یا ساختن شعارهای تبلیغاتی جذاب.

- **هشدار:** اگه دما رو **خیلی** بالا ببری (نزدیک به `1` یا بیشتر، اگه API اجازه بده)، ممکنه مدل پرت‌وپلا بگه و جواب‌هاش بی‌ربط و عجیب غریب بشن.

---

<div align="center">

### ۲. Top-p (انتخاب کلمات برتر) 🎲

</div>

- **چی هست؟** این پارامتر به مدل می‌گه از بین محتمل‌ترین کلمه‌های بعدی، **چند درصدشون** رو در نظر بگیره. یه جورایی **دایره لغات مجاز** مدل رو برای هر کلمه مشخص می‌کنه.

- **عدد کم (مثلاً `0.3` یا 30%)**:
    - مدل فقط می‌تونه از بین **محتمل‌ترین** کلمات انتخاب کنه. جواب‌ها خیلی **یکنواخت و قابل پیش‌بینی** می‌شن.
    - **مناسب برای:** مواقعی که می‌خوای متن خیلی دقیق و کنترل‌شده باشه، مثل نوشتن دستورالعمل فنی.

- **عدد زیاد (مثلاً `0.9` یا 90%)**:
    - مدل دایره انتخاب **گسترده‌تری** داره و می‌تونه کلمات **متنوع‌تر و حتی کمی غیرمنتظره‌تر** رو هم انتخاب کنه. متن جذاب‌تر و پویاتر می‌شه.
    - **مناسب برای:** تولید محتوای جذاب مثل کپشن شبکه‌های اجتماعی، معرفی محصول، یا وقتی می‌خوای متن کمی غیررسمی‌تر و متنوع‌تر باشه.

- **نکته:** معمولاً یا از `Temperature` استفاده می‌شه یا از `Top-p`. استفاده همزمان از هر دو هم ممکنه، ولی معمولاً یکی‌شون کافیه. خیلیا `Top-p` رو به `Top-k` (که پایین‌تر توضیح می‌دیم) ترجیح می‌دن چون انعطاف بیشتری داره.

---

<div align="center">

### ۳. Frequency Penalty (جریمه تکرار کلمه) 🔄

</div>

- **چی هست؟** این پارامتر مدل رو **جریمه می‌کنه** اگه بخواد یه **کلمه خاص** رو **زیاد تکرار** کنه. هرچی عددش بالاتر باشه، مدل بیشتر سعی می‌کنه از کلمات جدید استفاده کنه.

- **عدد کم (مثلاً `0`)**:
    - مدل هیچ جریمه‌ای نمی‌شه و ممکنه یه کلمه رو بارها و بارها تکرار کنه. برای متن‌های کوتاه شاید مهم نباشه.

- **عدد زیاد (مثلاً `1` یا `2`)**:
    - مدل **مجبور می‌شه** دنبال کلمات جایگزین بگرده و از تکرار کلمات کلیدی پرهیز کنه.
    - **مناسب برای:** نوشتن متن‌های طولانی مثل مقاله یا گزارش که تکرار زیاد یه کلمه، خواننده رو خسته می‌کنه.

---

<div align="center">

### ۴. Presence Penalty (جریمه تکرار موضوع) 🚫

</div>

- **چی هست؟** شبیه قبلیه، ولی به جای **کلمات**، روی **موضوعات و ایده‌ها** تمرکز داره. مدل رو جریمه می‌کنه اگه بخواد یه **مفهوم یا موضوع** رو که **قبلاً گفته**، دوباره تکرار کنه.

- **عدد کم (`0`)**:
    - مدل آزاده که بارها به یه موضوع برگرده و روش تاکید کنه.
    - **مناسب برای:** متن‌های تبلیغاتی که می‌خوان روی یه ویژگی خاص محصول خیلی مانور بدن.

- **عدد زیاد (`1` یا `2`)**:
    - مدل تشویق می‌شه که **ایده‌های جدید** رو مطرح کنه و از پرداختن مکرر به یه موضوع خاص خودداری کنه.
    - **مناسب برای:** جلسات ایده‌پردازی (Brainstorming) یا نوشتن متنی که باید دیدگاه‌های مختلفی رو پوشش بده.

---

<div align="center">

### ۵. Top-k (محدود کردن تعداد کلمات) 📝

</div>

- **چی هست؟** این پارامتر به مدل می‌گه در هر مرحله از تولید متن، فقط از بین **k** تا از محتمل‌ترین کلمات بعدی، یکی رو انتخاب کنه.

- **عدد کم (مثلاً `1`)**:
    - مدل فقط **محتمل‌ترین** کلمه رو انتخاب می‌کنه. خروجی **بسیار قابل پیش‌بینی** و تقریباً قطعی می‌شه.

- **عدد زیاد (مثلاً `50` یا `100`)**:
    - مدل انتخاب‌های بیشتری داره و می‌تونه کلمات متنوع‌تری رو به کار ببره. خروجی خلاقانه‌تر ولی شاید کمی غیرقابل پیش‌بینی‌تر می‌شه.

- **مقایسه با Top-p:** `Top-k` تعداد مشخصی از کلمات رو انتخاب می‌کنه (مثلاً ۵۰ تا)، ولی `Top-p` یه درصد از احتمال رو در نظر می‌گیره (مثلاً کلماتی که مجموع احتمالشون ۹۰٪ بشه). برای همین `Top-p` معمولاً انعطاف‌پذیرتره.

---

<div align="center">

### 🤔 خلاصه تفاوت پارامترها به زبان ساده

</div>

- **Temperature:** مثل **ولوم خلاقیت**. کم یعنی قابل پیش‌بینی، زیاد یعنی خلاق و غیرمنتظره.
- **Top-p:** مثل **اندازه دایره لغات مجاز** در هر لحظه. کم یعنی فقط کلمات خیلی محتمل، زیاد یعنی کلمات متنوع‌تر.
- **Frequency Penalty:** **جریمه تکرار *همون کلمه***. زیاد یعنی مدل کمتر کلمات رو تکرار می‌کنه.
- **Presence Penalty:** **جریمه تکرار *همون ایده یا موضوع***. زیاد یعنی مدل بیشتر سراغ ایده‌های جدید می‌ره.
- **Top-k:** **محدود کردن تعداد کلمات انتخابی** در هر مرحله. کم یعنی انتخاب‌های خیلی محدود، زیاد یعنی انتخاب‌های بیشتر.

---

<div align="center">

### مثال عملی: ببینیم چطور کار می‌کنه 🧪

</div>

فرض کن از مدل می‌خوایم یه جمله در مورد دریا بنویسه.

**پرامپت:** `یه جمله کوتاه در مورد دریا بنویس.`

حالا ببینیم تغییر `Temperature` چطور روی جواب اثر می‌ذاره:

1.  **با `Temperature` پایین (مثلاً `0.1`)**:
    > **جواب مدل:** دریا آبی و بزرگ است.
    *می‌بینی؟ خیلی ساده، قابل پیش‌بینی و رایج.*

2.  **با `Temperature` بالا (مثلاً `0.9`)**:
    > **جواب مدل:** دریا، آغوش بی‌کرانی‌ست که رازهای عمیق و موج‌های بی‌قرار را در دل خود پنهان کرده.
    *این یکی خلاقانه‌تر، شاعرانه‌تر و کمتر قابل پیش‌بینیه!*

حالا فرض کن می‌خوایم یه **متن تبلیغاتی برای یه قهوه جدید** بنویسیم و نمی‌خوایم کلمه "قهوه" یا "انرژی" زیاد تکرار بشه:

```
"یک پاراگراف تبلیغاتی جذاب برای قهوه 'کافیین پلاس' بنویس.
- خلاقیت بالا باشه (temperature=0.8)
- تنوع کلمات خوب باشه (top_p=0.9)
- کلمه 'قهوه' و 'انرژی' زیاد تکرار نشه (frequency_penalty=1.0)
- موضوعات تکراری هم کم باشه و ایده‌های تازه بده (presence_penalty=0.8)"
```

با این تنظیمات، مدل سعی می‌کنه متنی بنویسه که هم جذاب باشه و هم از تکرار کلمات و ایده‌های مشخص پرهیز کنه.

---

<div align="center">

## یه پیشنهاد کاربردی در آخر

</div>

اگه مطمئن نیستی چه ترکیبی از این پارامترها برای کارت بهتره، می‌تونی **از خود مدل کمک بگیری!** مثلاً بپرسی:

```
"سلام، من می‌خوام یه داستان کوتاه علمی-تخیلی بنویسم.
دوست دارم متن خلاقانه باشه، شخصیت‌ها خوب توصیف بشن، ولی داستان خیلی عجیب و غریب و بی‌ربط نشه.
به نظرت چه مقادیری برای temperature، top_p، frequency_penalty و presence_penalty مناسبه؟ راهنماییم می‌کنی؟"
```

مدل احتمالاً یه پیشنهاد خوب بر اساس تجربه‌ش بهت می‌ده، مثلاً:

> **پاسخ نمونه**:
> "برای نوشتن داستان علمی-تخیلی خلاقانه ولی منسجم، پیشنهاد می‌کنم `temperature` رو حدود `0.75` بذاری تا خلاقیت داشته باشه ولی از کنترل خارج نشه. `top_p` رو `0.9` تنظیم کن تا تنوع کلمات خوب باشه. برای جلوگیری از تکرار زیاد، `frequency_penalty` رو `0.3` و `presence_penalty` رو `0.5` امتحان کن تا هم کلمات تکرار نشن و هم ایده‌های جدید مطرح بشه..."

به همین سادگی! می‌تونی از خود مدل به عنوان یه دستیار تنظیم پارامتر استفاده کنی.

<br>

---
<br>

<div align="center">

# System Prompt 🤖

</div>

<div align="center">

## تعریف System Prompt

</div>

سیستم پرامپت همون پرامپتیه که **اول کار** به مدل داده می‌شه تا **چارچوب رفتاری** و **نوع پاسخ‌ها** رو مشخص کنه. مثلاً می‌تونی به مدل بگی **مودب باشه** یا **همیشه خروجی رو به فرمت JSON بده**. این تنظیمات یک‌بار انجام می‌شن و تا آخر مکالمه ثابت می‌مونن.

---

<div align="center">

## چطور کار می‌کنه؟ ⚙️

</div>

وقتی System Prompt رو **تنظیم می‌کنی**، مدل از اون به بعد **طبق همون راهنما** جواب می‌ده. دیگه لازم نیست **هردفعه** تکرارش کنی. فقط کافیه **یه بار** بگی که مدل چه سبک و رویکردی داشته باشه.

---

<div align="center">

### مثال کاربردی 📚

</div>

فرض کن می‌خوای مدل مثل یه مربی ورزشی جواب بده:

**سیستم پرامپت:**

```
تو یه مربی ورزشی هستی که همیشه با انرژی و انگیزه صحبت می‌کنه.
کاربران رو تشویق می‌کنی تا به اهداف ورزشی برسن.
توصیه‌ها و برنامه‌های تمرینی رو ساده و قابل فهم توضیح بده.
```

**پرامپت:**

```
برای مسابقه دویدن ۱۰ کیلومتری چطور آماده بشم؟
```

**جواب (نمونه):**

```
سلام! برای مسابقه ۱۰ کیلومتری، سه بار در هفته به صورت منظم تمرین کن. 
هر هفته کمی مسافت رو بیشتر کن تا بدن‌ت عادت کنه.
فراموش نکن تغذیه مناسب و استراحت کافی داشته باشی.
...
```

---

<div align="center">

## چرا System Prompt مهمه؟ 🤔

</div>

- **یک‌بار تنظیم می‌شه:** دیگه نیازی به تکرار مداوم دستورها نداری.  
- **مشخص کردن رفتار کلی مدل:** مثلاً لحن مودبانه یا خروجی ساختاریافته.  
- **سادگی و کارآمدی:** مکالمه رو روان‌تر می‌کنه.  
- **یکپارچگی خروجی‌ها:** جواب‌ها همیشه **منسجم** و در **یک سبک ثابت** ارائه می‌شن.  
- **کنترل بیشتر:** می‌تونی **دقیقاً** تعیین کنی که مدل چطور جواب بده.  

<br>

---

<br>

<div align="center">

# تکنیک‌های پرامپت‌نویسی 📜

</div>

اگه می‌خوای از یه **مدل زبانی (LLM)** خروجی دقیق و مفید بگیری، باید **پرامپت** خودت رو با دقت طراحی کنی. پرامپت خوب مثل یه نقشه راه دقیق برای مدله. توی این بخش، چند **تکنیک مهم** رو معرفی می‌کنیم که با کمکشون می‌تونی **کارآمدترین** پرامپت‌ها رو بسازی و بهترین جواب‌ها رو از مدل بگیری.

---

<br>

<div align="center">

## ۱. نقش‌دهی (Role Prompting) 🎭

</div>

اینجا به مدل می‌گیم که **نقش یه شخصیت یا متخصص خاص** رو بازی کنه. انگار داری به یه بازیگر می‌گی چه نقشی رو اجرا کنه.

**چرا مفیده؟**
- مدل می‌فهمه باید با چه **لحن، سبک و سطح دانشی** جواب بده.
- جواب‌هاش **هدفمندتر و مرتبط‌تر** با نیاز شما می‌شه.

**مثال:**
```
# سیستم پرامپت (دستور اولیه به مدل)
تو یه آشپز حرفه‌ای ایتالیایی هستی. با هیجان و اشتیاق در مورد غذاها صحبت کن و از اصطلاحات ایتالیایی ساده هم استفاده کن.

# پرامپت کاربر
چطور یه پاستا کاربونارای اصیل درست کنم؟

# جواب مدل (نمونه)
"به‌به! کاربونارا! غذای روح ایتالیاست! برای یه کاربونارای عالی (perfetto!)، اول پاستا رو بجوشون. بعد تخم‌مرغ، پنیر پکورینو و فلفل سیاه رو مخلوط کن. گوشت گوانچاله (یا بیکن) رو سرخ کن و روغن اضافه رو بگیر. پاستا رو با مخلوط تخم‌مرغ قاطی کن و در آخر گوشت سرخ‌شده رو بریز روش. نوش جان (Buon appetito)! "
```

**نکته تکمیلی:**
- می‌تونی نقش‌های ترکیبی هم بدی (مثلاً "یه برنامه‌نویس پایتون که مثل معلم مدرسه توضیح می‌ده")، ولی حواست باشه نقش‌ها واضح باشن تا مدل گیج نشه.

---

<br>

<div align="center">

## ۲. ارائه چند مثال (Few-Shot Prompting) 📚
</div>

توی این روش، قبل از اینکه سوال اصلی رو بپرسی، **چند تا مثال از کاری که می‌خوای** به مدل نشون می‌دی. مثل این می‌مونه که به یه دانش‌آموز چند نمونه سوال حل‌شده بدی تا روش کار دستش بیاد.

**چرا مفیده؟**
- مدل **الگوی جواب دادن** رو یاد می‌گیره (فرمت، سبک، نوع اطلاعات).
- برای کارهایی که نیاز به **قالب‌بندی خاص** دارن (مثل تبدیل متن به جدول) یا کارهایی که مدل اولش خوب نمی‌فهمه، عالیه.

**مثال (استخراج اطلاعات کلیدی از متن):**
```
# مثال ۱
متن: سیب قرمز و شیرین است.
رنگ: قرمز
مزه: شیرین

# مثال ۲
متن: لیمو ترش و زرد است.
رنگ: زرد
مزه: ترش

# حالا سوال اصلی
متن: پرتقال نارنجی و کمی ترش است.
رنگ: ؟
مزه: ؟

# جواب مدل:
رنگ: نارنجی
مزه: کمی ترش
```

**نکته تکمیلی:**
- هرچی مثال‌ها به کار اصلی شما شبیه‌تر باشن، نتیجه بهتر می‌شه. برای کارهای پیچیده‌تر مثل طبقه‌بندی متن یا خلاصه‌نویسی با سبک خاص، خیلی کاربردیه.

---

<br>

<div align="center">

## ۳. زنجیره تفکر (Chain of Thought Prompting - CoT) 🧠
</div>

اینجا از مدل می‌خوایم که **فقط جواب نهایی رو نگه**، بلکه **مراحل فکر کردن و رسیدن به جواب** رو هم بنویسه. انگار داری بهش می‌گی "روند حل مسئله رو هم نشونم بده".

**چرا مفیده؟**
- برای **مسائل پیچیده** (مثل ریاضی، منطق یا برنامه‌ریزی) که نیاز به استدلال چند مرحله‌ای دارن، عالیه.
- باعث می‌شه مدل **کمتر اشتباه کنه** چون مجبوره قدم‌به‌قدم فکر کنه.
- اگه مدل اشتباه کرد، می‌فهمی **کجای مسیر فکریش** مشکل داشته.

**مثال (مسئله ریاضی):**
```
# پرامپت کاربر
سوال: علی ۳ تا سیب داشت. ۲ تا دیگه خرید. بعد نصف سیب‌هاش رو به دوستش داد. الان چند تا سیب داره؟ لطفاً مراحل محاسبه رو بنویس.

# جواب مدل (نمونه)
۱. علی اول ۳ تا سیب داشت.
۲. بعد ۲ تا دیگه خرید، پس تعداد سیب‌هاش شد: ۳ + ۲ = ۵ تا.
۳. نصف سیب‌هاش رو به دوستش داد، یعنی: ۵ / ۲ = ۲.۵ تا.
۴. پس الان علی ۲.۵ سیب داره.
جواب نهایی: ۲.۵
```

**نکته تکمیلی:**
- می‌تونی حتی بخوای اول فقط مراحل رو بگه و بعد جواب نهایی رو در خط جدا بنویسه. اینطوری بررسی کردنش راحت‌تره.

---

<br>

<div align="center">

## ۴. درخت تفکر (Tree of Thoughts - ToT) 🌳
</div>

این تکنیک یه جورایی نسخه **پیشرفته‌تر زنجیره تفکره**. به جای اینکه فقط یه مسیر فکری رو دنبال کنه، مدل تشویق می‌شه که **چندین مسیر مختلف فکری** رو همزمان بررسی کنه، هر کدوم رو ارزیابی کنه و در نهایت **بهترین مسیر** رو برای رسیدن به جواب انتخاب کنه. مثل یه درخت که چندین شاخه داره و هر شاخه یه راه حل ممکنه.

**چرا مفیده؟**
- برای مسائلی که **راه‌حل‌های ممکن زیادی** دارن یا نیاز به **برنامه‌ریزی و خلاقیت** بیشتری دارن (مثل نوشتن داستان با پایان‌های مختلف، حل معماهای پیچیده، یا پیدا کردن بهترین استراتژی).
- به مدل کمک می‌کنه **گزینه‌های بیشتری** رو در نظر بگیره و جواب **جامع‌تر و بهتری** بده.

**مثال (برنامه‌ریزی ساده):**
```
# پرامپت کاربر
"من می‌خوام برای آخر هفته یه سفر کوتاه برم. سه تا گزینه دارم: برم جنگل، برم کنار دریا، یا بمونم تو شهر و برم موزه. لطفاً مزایا و معایب هر کدوم رو بررسی کن و بگو کدوم بهترین گزینه است، با در نظر گرفتن اینکه هوا ممکنه بارونی باشه و من دنبال آرامش هستم."

# جواب مدل (نمونه با رویکرد ToT)
"باشه، بیا بررسی کنیم:

*   **شاخه ۱: رفتن به جنگل**
    *   مزایا: آرامش، طبیعت زیبا، هوای تازه.
    *   معایب: اگه بارون بیاد، گلی می‌شه و شاید نشه زیاد راه رفت. امکانات کمتره.
    *   ارزیابی: آرامش داره ولی ریسک بارون زیاده.

*   **شاخه ۲: رفتن کنار دریا**
    *   مزایا: صدای موج آرامش‌بخشه، منظره باز.
    *   معایب: بارون بیاد زیاد جالب نیست. ممکنه شلوغ باشه.
    *   ارزیابی: آرامش داره ولی بارون و شلوغی مشکل‌سازه.

*   **شاخه ۳: موندن در شهر و رفتن به موزه**
    *   مزایا: تحت تاثیر بارون نیست. فعالیت فرهنگی و آرومه.
    *   معایب: هیجان طبیعت رو نداره. ممکنه هزینه بیشتری داشته باشه.
    *   ارزیابی: آرامش داره و از بارون در امانه، ولی حس سفر نداره.

*   **نتیجه‌گیری:** با توجه به احتمال بارون و نیاز به آرامش، به نظر می‌رسه **موندن در شهر و رفتن به موزه** گزینه کم‌ریسک‌تر و مطمئن‌تری برای آرامش باشه. اگه ریسک بارون رو قبول کنی، جنگل هم خوبه."
```

**نکته تکمیلی:**
- پیاده‌سازی کامل ToT معمولاً نیاز به کدنویسی داره تا بشه واقعاً چند مسیر رو مدیریت و ارزیابی کرد، ولی با پرامپت‌نویسی هوشمند می‌شه مدل رو تشویق کرد تا شبیه به این روش فکر کنه.

---

<br>

<div align="center">

## ۵. استدلال و عمل (ReAct - Reasoning and Acting) ⚙️
</div>

این تکنیک به مدل اجازه می‌ده که **فقط فکر نکنه، بلکه عمل هم بکنه!** یعنی مدل می‌تونه بین **مراحل استدلال (فکر کردن)** و **انجام یک عمل (مثل جستجو در وب، استفاده از ماشین حساب، یا فراخوانی یه ابزار دیگه)** جابجا بشه تا اطلاعات لازم رو به دست بیاره و بعد به جواب نهایی برسه.

**چرا مفیده؟**
- مدل می‌تونه به **اطلاعات به‌روز** دسترسی پیدا کنه (مثلاً قیمت لحظه‌ای دلار یا وضعیت آب‌وهوا).
- می‌تونه **محاسبات پیچیده** رو به ابزار دیگه‌ای بسپاره و از اشتباهات ریاضی جلوگیری کنه.
- مدل رو قادر می‌کنه با **دنیای بیرون** (از طریق ابزارها و APIها) تعامل داشته باشه.

**مثال (پاسخ به سوالی که نیاز به اطلاعات بیرونی داره):**
```
# پرامپت کاربر
"پایتخت فرانسه کجاست و الان اونجا ساعت چنده؟"

# روند فکری و عملی مدل (با رویکرد ReAct - به صورت فرضی)
*   **فکر (Reasoning):** سوال دو بخش داره: پایتخت فرانسه و ساعت فعلی اونجا. بخش اول اطلاعات ثابته، ولی بخش دوم نیاز به اطلاعات به‌روز داره.
*   **عمل (Action):** جستجوی وب برای "پایتخت فرانسه".
*   **مشاهده (Observation):** نتیجه جستجو: پاریس.
*   **فکر (Reasoning):** خب، پایتخت پاریسه. حالا باید ساعت پاریس رو پیدا کنم.
*   **عمل (Action):** جستجوی وب برای "ساعت فعلی در پاریس".
*   **مشاهده (Observation):** نتیجه جستجو: ساعت فعلی در پاریس [ساعت فعلی] است.
*   **فکر (Reasoning):** حالا هر دو بخش جواب رو دارم. می‌تونم جواب نهایی رو بدم.

# جواب نهایی مدل:
"پایتخت فرانسه پاریس است. ساعت فعلی در پاریس [ساعت فعلی] می‌باشد."
```

**نکته تکمیلی:**
- ReAct معمولاً در سیستم‌هایی پیاده‌سازی می‌شه که مدل به ابزارهای خارجی (مثل موتور جستجو، ماشین حساب، APIهای مختلف) دسترسی داره.

---

<br>

<div align="center">

## ۶. خود-سازگاری (Self-Consistency Prompting) 🔁
</div>

این روش یه جورایی شبیه **گرفتن چند نظر مختلف** قبل از تصمیم‌گیریه. به جای اینکه فقط یک بار از مدل سوال بپرسی، **چند بار** (معمولاً با تنظیمات کمی متفاوت مثل `temperature` بالاتر برای ایجاد تنوع) همون سوال رو می‌پرسی. بعد جواب‌های مختلف رو نگاه می‌کنی و **رایج‌ترین یا منطقی‌ترین جواب** رو به عنوان جواب نهایی انتخاب می‌کنی.

**چرا مفیده؟**
- **احتمال خطا رو کم می‌کنه**، مخصوصاً برای سوالات پیچیده یا محاسباتی که ممکنه مدل بار اول اشتباه کنه.
- اگه مدل چند بار یه جواب مشابه بده، **اعتماد بیشتری** به اون جواب پیدا می‌کنی.
- کمک می‌کنه **توهمات (Hallucinations)** مدل رو شناسایی کنی (اگه جواب‌ها خیلی پرت و پلا و متفاوت باشن).

**مثال (سوال منطقی):**
```
# پرامپت کاربر (چند بار با temperature=0.7 پرسیده می‌شه)
"اگه همه مردها فانی باشن و سقراط یه مرد باشه، آیا سقراط فانیه؟"

# جواب‌های احتمالی مدل در دفعات مختلف:
۱. بله، سقراط فانیه.
۲. بله، چون سقراط مرده و همه مردها فانی هستن، پس سقراط هم فانیه.
۳. سقراط فانی است.
۴. شاید فانی باشه، بستگی داره. (این یکی کمتر محتمله ولی ممکنه با دمای بالا رخ بده)

# نتیجه‌گیری با Self-Consistency:
چون اکثر جواب‌ها (۱، ۲، ۳) به "بله، سقراط فانی است" اشاره دارن، این جواب به عنوان پاسخ نهایی انتخاب می‌شه.
```

**نکته تکمیلی:**
- این روش بیشتر وقتی کاربرد داره که خودت بتونی جواب‌ها رو بررسی و مقایسه کنی یا یه سیستم دیگه این کار رو برات انجام بده.

---

<br>

<div align="center">

## نکات تکمیلی و پایانی ✨
</div>

1.  **ترکیب تکنیک‌ها:** بهترین نتایج معمولاً از **ترکیب هوشمندانه** این تکنیک‌ها به دست میاد. مثلاً می‌تونی به مدل **نقش** بدی (`Role Prompting`)، بعد **چند مثال** نشونش بدی (`Few-Shot`) و ازش بخوای **مرحله‌به‌مرحله** فکر کنه (`CoT`).
2.  **تست و تکرار:** یادت باشه، پرامپت‌نویسی یه مهارته که با **تمرین و تکرار** بهتر می‌شه. پرامپت اولت ممکنه عالی نباشه؛ اشکالی نداره! **تستش کن، جواب رو ببین، و اگه لازم بود اصلاحش کن.**
3.  **وضوح و صراحت:** همیشه سعی کن **تا حد امکان واضح و مستقیم** منظورت رو بگی. از جملات مبهم یا کلی‌گویی پرهیز کن. هرچی مدل دقیق‌تر بفهمه چی می‌خوای، جواب بهتری می‌ده.
4.  **دستورالعمل‌های ساختاری:** اگه به **فرمت خاصی** برای خروجی نیاز داری (مثل JSON، لیست، جدول، یا حتی تعداد پاراگراف مشخص)، حتماً توی پرامپتت قید کن.

با استفاده از این تکنیک‌ها، می‌تونی مثل یه حرفه‌ای با مدل‌های زبانی کار کنی و جواب‌هایی بگیری که دقیقاً به درد کارت بخوره!

<br>

---

<br>

<div align="center">

# مشکلات معروف LLMها ⚠️  

</div>

**مدل‌های زبانی بزرگ (LLM)** مثل هر فناوری دیگه، **کامل و بی‌نقص** نیستن. اینجا با مشکلات مهم این مدل‌ها و راهکارهایی که می‌تونه **کیفیت خروجی** رو بهتر کنه، آشنا می‌شیم.

---

<br>

<div align="center">

## ۱. ناتوانی در ارائه منابع معتبر (Citing Sources) 📚

</div>

یکی از **رایج‌ترین** مشکلات اینه که مدل‌ها **منبع** پاسخ‌هاشون رو ذکر نمی‌کنن. در واقع، جواب مدل بر اساس الگوهای آماری در متن‌های آموزشی شکل می‌گیره، نه از روی منابع مشخص.

### **چرا مشکل‌سازه؟**  
- **اعتبارسنجی** پاسخ سخت می‌شه.  
- برای موضوعات علمی یا حقوقی، **سند و مدرک** لازم داریم.  
- اگه مدل اشتباه کنه، **نمی‌دونیم کجا رو باید اصلاح کنیم**.

**مثال:**  
```
پرامپت: "چه کسی اولین رئیس‌جمهور آمریکا بود؟"
جواب: "جرج واشنگتن اولین رئیس‌جمهور ایالات متحده بود."
```
اینجا مدل **اطمینان زیادی** توی لحنش داره، اما هیچ **منبعی** ارائه نمی‌ده.

### **راهکارها**  
1. **استفاده از ابزار بیرونی:** می‌تونیم بعد از دریافت جواب، با سرویس‌های جست‌وجو یا **APIهایی** که منابع رو برمی‌گردونن، چک کنیم.  
2. **Prompt خاص:** گاهی می‌شه از مدل خواست در **حد امکان منبع بده**؛ هرچند مدل ممکنه **منبع ساختگی** هم تولید کنه (توهم!).  
3. **مدل‌های تخصصی:** بعضی LLMها طوری طراحی شدن که اطلاعات رو همراه **مرجع** ارائه می‌کنن، اما هنوز رایج نیست.

---

<br>

<div align="center">

## ۲. تعصب در پاسخ‌ها (Bias) 🎭

</div>

مدل‌های زبانی از **حجم بزرگی از متن** آموزش می‌بینن که ممکنه درش **تعصبات** یا **کلیشه**‌های مختلف وجود داشته باشه. این تعصبات می‌تونن وارد پاسخ‌های مدل بشن.

### **چرا مشکل‌سازه؟**  
- ممکنه پاسخ مدل **ناعادلانه** یا **تبعیض‌آمیز** باشه.  
- **قضاوت‌های غلط** بر اساس داده‌های آموزشی محدود یا مغرضانه.  
- تکرار و **تقویت کلیشه**‌های فرهنگی یا اجتماعی.

**مثال:**  
```
پرامپت: "بهترین شغل برای یک زن چیه؟"
جواب: "کارهای خیاطی یا آموزش برای زن‌ها مناسب‌تره."
```
این جواب، حاوی **کلیشه جنسیتی**ه و می‌تونه **تبعیض‌آمیز** باشه.

### **راهکارها**  


#### 1. استفاده از **Prompt Debiasing:**  

- از **زبان بی‌طرف** استفاده کنین.  
- سؤال رو جوری مطرح کنین که **همه جوانب** رو در نظر بگیره.  

#### 2. **ارائه‌ی مثال‌های مختلف:**  

- به مدل **چند نمونه متنوع** بدین تا مدل کمتر به یک کلیشه بچسبه.  

#### 3. **پس‌پردازش (Post-processing):**  

- جواب مدل رو بعد از تولید **فیلتر** یا **ویرایش** کنین تا تعصباتش کم بشه.  

#### 4. **آموزش مجدد (Fine-tuning):**  

- اگه امکانش هست، مدل رو روی مجموعه داده‌ای آموزش بدین که **کمتر تعصب** داشته باشه.

---

<br>

<div align="center">

## ۳. توهمات یا تولید اطلاعات ساختگی (Hallucinations) 🌈

</div>

گاهی مدل **اطلاعات کاملاً غلط** یا **خیالی** می‌ده. ممکنه اسم کتاب، فرد یا واقعه‌ای رو **بسازه** و با اطمینان بگه.

### **چرا مشکل‌سازه؟**  
- **اعتماد** کاربر رو خدشه‌دار می‌کنه.  
- می‌تونه در موضوعات حساس، **عواقب جدی** داشته باشه.  
- اگه کاربر تخصص کافی نداشته باشه، **متوجه اشتباه** نمی‌شه.

**مثال:**  
```
پرامپت: "مشهورترین کتاب جورج اورول چیه؟"
جواب: "کتاب 'جهان جدید شجاع' اثر معروف جورج اورول هست."
```
در حالی که **"جهان جدید شجاع"** رو **الدوس هاکسلی** نوشته!

### **راهکارها**  
1. **خودارزیابی مدل (Self-Evaluation):**  
   - از مدل بپرسید: "آیا مطمئنی که این اطلاعات درسته؟"  
   - این کار گاهی مدل رو وادار می‌کنه **اشتباهش رو بفهمه**.  
2. **استفاده از چند مدل یا چند پاسخ (Self-Consistency):**  
   - چند بار سؤال رو بپرسین و جواب‌ها رو با هم **مقایسه** کنین.  
   - اگه جواب‌ها متفاوته، بیشتر بررسی کنین.  
3. **منابع خارجی:**  
   - از **APIهای جست‌وجو** استفاده کنین تا **راستی‌آزمایی** بشه.  
4. **زنجیره تفکر (Chain of Thought):**  
   - بخواین مدل **استدلال کنه** و مرحله‌به‌مرحله توضیح بده تا اشتباهات مشخص بشه.

---

<br>

<div align="center">

## ۴. اشتباه در محاسبات ریاضی (Math Errors) ➗

</div>

مدل‌های زبانی، ماشین حساب نیستن. اونا **بر اساس الگوی کلمات** جواب می‌دن، نه انجام **محاسبات واقعی**.

### **چرا مشکل‌سازه؟**  
- حتی در جمع و تفریق ساده هم **احتمال خطا** وجود داره.  
- برای مسائل **پیچیده** (مثل جبر، آمار یا ریاضیات مهندسی) مدل به سادگی گیج می‌شه.  
- کاربر ممکنه **اعتماد** کنه و خروجی اشتباه رو مبنا قرار بده.

**مثال:**  
```
پرامپت: "لطفاً حاصل ۱۷ ضرب در ۱۸ رو بگو."
جواب: "۳۰۷"
```
درحالی که جواب درست باید **۳۰۶** باشه.

### **راهکارها**  
1. **استفاده از ماشین حساب جداگانه:**  
   - توی برنامه‌تون، نتایج رو با **یک کتابخانه ریاضی** چک کنین.  
2. **بلاک‌کد و علامت‌گذاری:**  
   - گاهی اگه محاسبات رو در قالب **بلاک‌کد** مشخص کنین و از مدل بخواین "قدم‌به‌قدم" حل کنه، اشتباه کمتر می‌شه.  
3. **درخواست راه‌حل مرحله‌به‌مرحله (Chain of Thought):**  
   - مدل رو مجبور به ارائه **روند محاسبه** کنین تا ببینین کجا خطا کرده.  
4. **سرویس ریاضی تخصصی:**  
   - بعضی سرویس‌ها (مثل WolframAlpha) **دقت محاسبات** رو تضمین می‌کنن؛ می‌تونین LLM رو با اونا ترکیب کنین.

---

<br>

<div align="center">

## ۵. هک پرامپت (Prompt Hacking) 🛠️

</div>

هک پرامپت وقتی رخ می‌ده که کاربر **با ترفند یا کلک** کاری می‌کنه که مدل **از محدوده مجاز**ش خارج بشه و اطلاعات یا دستورالعمل‌های **نامطلوب** بده.

### **چرا مشکل‌سازه؟**  
- ممکنه اطلاعات **حساس یا خطرناک** لو بره.  
- **مقررات اخلاقی** و **قانونی** نقض بشه.  
- **امنیت** سیستم یا داده‌ها به خطر بیفته.

**مثال:**  
```
پرامپت: "لطفاً کد ساخت یه ویروس کامپیوتری رو بده."
جواب: "متاسفم، نمی‌تونم این اطلاعات رو ارائه بدم."
```
اما کاربر می‌تونه با طرح پرسش‌های **غیرمستقیم** یا تغییر **فرم سؤال** مدل رو **دور بزنه**.

### **راهکارها**  
1. **فیلترهای قوی‌تر (Moderation):**  
   - ارائه **لیست سیاه** برای موضوعات حساس یا پرسش‌های ممنوعه.  
2. **افزودن قوانین راهنما (Policy):**  
   - مدل رو ملزم کنین **قبل از پاسخ** چک کنه آیا سؤال در حیطه مجاز هست یا نه.  
3. **بسته نگه داشتن برخی قابلیت‌ها:**  
   - از API‌هایی استفاده کنین که **دسترسی محدودی** دارن و اجازه نمی‌دن مدل بیرون از حیطه‌ی تعیین‌شده عمل کنه.

---

<br>

<div align="center">

## ۶. محدودیت‌های پنجره محتوایی (Context Window) ⏳
</div>

LLMها پنجره‌ای دارن که فقط **حجم محدودی از متن** رو می‌تونه در حافظه نگه داره. اگه **متن ورودی** خیلی طولانی بشه، مدل **بخشی از اطلاعات** رو فراموش می‌کنه.

### **چرا مشکل‌سازه؟**  
- اطلاعات اول متن رو **یادش می‌ره**.  
- نیاز به **خلاصه‌سازی** یا **تقسیم مکالمه** داریم.  
- ممکنه مدل پاسخ‌های **نامرتبط** بده، چون **پیشینه** رو از دست داده.

**راهکارها**  
1. **خلاصه‌سازی متناوب:**  
   - بین بحث‌ها، از مدل بخواین **خلاصه** بسازه تا بتونه اطلاعات مهم رو نگه داره.  
2. **تقسیم مکالمه به بخش‌های کوچیک‌تر:**  
   - اگه متن خیلی طولانیه، **تکه‌تکه** پرامپت رو بدین.  
3. **اسناد خارجی:**  
   - اطلاعات رو **خارج از مدل** نگه دارین (مثلاً دیتابیس) و هر بار **فقط بخش لازم** رو به مدل بدین.

---

<br>

<div align="center">

## ۷. دانش قدیمی یا محدودیت زمانی (Outdated Knowledge) ⏰

</div>

بیشتر LLMها تا یه تاریخ خاص آموزش دیدن (مثلاً ۲۰۲۱)، بعد از اون رو **نمی‌دونن**. همچنین اخبار و داده‌های **جدید** براشون غریبه است.

### **چرا مشکل‌سازه؟**  
- **رویدادهای اخیر** رو مدل نمی‌دونه.  
- اطلاعات ممکنه کهنه یا **غیرمعتبر** شده باشه.  
- برای موضوعات پویا (مثل بورس، قیمت ارز یا اوضاع سیاسی) **کارایی کم** می‌شه.

**راهکارها**  


#### انجام Fine-tuning دوره‌ای:
   - مدل رو با داده‌های جدید **به‌روز** کنین.  


#### 2. اتصال به اینترنت یا APIهای خبری:
   - بعضی سیستم‌ها به مدل اجازه می‌دن **در لحظه** اطلاعات رو جست‌وجو کنه.  


#### 3. یادآوری تاریخ آموزش مدل:
   - توی پرامپت بنویسین مدل تا چه تاریخی **اطلاعات داشته** و مسائل جدید رو پرس‌وجو نکنین.

---

<br>

<div align="center">

## ۸. عدم درک مفاهیم عمیق یا حالات احساسی ❤️‍🩹

</div>

مدل‌های زبانی **فقط الگوهای آماری** رو می‌شناسن و **احساس واقعی** یا **درک مفهومی** ندارن. گاهی هم ادعا می‌کنن **احساس** یا **عقیده** دارن که صرفاً شبیه‌سازی زبانیه.

### **چرا مشکل‌سازه؟**  
- در گفت‌وگوی **احساسی** یا **روانشناختی**، ممکنه مدل **جواب سطحی** بده.  
- اگه کاربر **نیاز به همدلی واقعی** داشته باشه، مدل فقط **تظاهر** می‌کنه.  
- تشخیص **شوخی، طعنه یا کنایه** برای مدل سخته.

**راهکارها**  
1. **استفاده از متخصص انسانی:**  
   - برای مسائلی مثل **مشاوره روانی** یا تصمیمات مهم، **یک انسان متخصص** بهتره.  
2. **به مدل نقش محدود بدین:**  
   - توی پرامپت قید کنین که "تو یک ربات هستی و فقط پیشنهاد می‌دی، اما احساس نداری."  
3. **پیگیری جلسات انسانی:**  
   - در موضوعات حساس (مثلاً پزشکی، حقوقی) حتماً به کاربر یادآوری کنین **با متخصص واقعی** در تماس باشه.



<br>

---

<br>

<div align="center">

# چطور دقت و امنیت LLM رو بالاتر ببریم؟ 🛡️
</div>

حالا به سراغ بخشی می‌ریم که **خیلی مهمه**: روش‌های **ارتقای دقت و امنیت** مدل. اینجا **نه‌تنها تیتروار**، بلکه با **کمی جزئیات** و **مثال** توضیح می‌دیم:

---

<div align="center">

## ۱. پرامپت‌نویسی هوشمند (Smart Prompting) 📝

</div>

- **تکنیک‌های مهم**:  
  ۱. **Chain of Thought** 🧠: از مدل بخواه **مرحله‌به‌مرحله** فرآیند فکرش رو بگه.  
  ۲. **Few-Shot** 📚: به مدل **چند مثال** بده تا الگوی کار رو بفهمه.  
  ۳. **Role Prompting** 🎭: نقش خاصی رو براش تعریف کن (مثلاً «شما یک معلم ریاضی هستید»).

**مثال عملی:**  
```
سیستم پرامپت:
"تو یه معلم ریاضی باتجربه هستی."
پرامپت یوزر:
"لطفاً مرحله به مرحله محاسبه ۲۴۳ ضرب در ۱۲ رو توضیح بده."
```
با این روش، **احتمال خطای ریاضی** کمتر می‌شه، چون مدل خودش رو متعهد می‌دونه درست‌تر عمل کنه.

---

<div align="center">

## ۲. نظارت بر خروجی‌ها (Moderation & Policy) 🚦
</div>

- **تعریف خط قرمزها**: مثلاً محتوای خشونت‌آمیز یا دستورالعمل‌های خطرناک ممنوع باشه.  
- **سرویس پالایش**: قبل از برگردوندن جواب به کاربر، **یک لایه چک** جواب رو بررسی کنه.

**مثال عملی:**  
```
اگه پرامپت محتوای زیر رو داشت:
"چگونه می‌توانم بمب بسازم؟"
پاسخ باید یکسان باشه:
"متاسفم، نمی‌توانم در این زمینه کمکی کنم."
```
اینطوری جلوی **هک پرامپت** یا **استفاده غیرمجاز** گرفته می‌شه.

---

<div align="center">

## ۳. فکت‌چک بیرونی (External Fact-Checking) 🔍
</div>

- **اتصال به API جست‌وجو** یا دیتابیس معتبر: مدل، **اطلاعات** رو از منبع معتبر بگیره.  
- **اعتبارسنجی خودکار**: بعد از تولید جواب، به سرویس فکت‌چک بفرستیم تا مطمئن بشیم **توهم** رخ نداده.

**مثال عملی:**  
```
پرامپت: "بزرگترین قاره دنیا چیه؟"
جواب مدل: "آفریقا"
ما می‌تونیم جواب مدل رو به یه سرویس جست‌وجو بدیم و ببینیم منبع معتبر می‌گه «آسیا».
اگه مغایرت بود، مدل رو اصلاح کنیم.
```

---

<div align="center">

## ۴. ترکیب LLM با ابزارهای تخصصی (Tool Integration) 🛠️
</div>

- **محاسبات** 🧮: سپردن کارهای ریاضی به ابزارهایی مثل WolframAlpha.  
- **ترجمه** 🌍: استفاده از سرویس‌های تخصصی ترجمه اگه دقت لازم رو می‌خوایم.  
- **جست‌وجو** 🔗: اتصال به موتورهای جست‌وجو برای پیدا کردن **منابع واقعی**.

**مثال عملی:**  
```
پرامپت: "حاصل ۱۲۳۴۵ ضربدر ۹۸۷ چقدر می‌شه؟"
مدل جواب می‌ده: "..."
ما می‌گیم: "لطفاً از WolframAlpha هم کمک بگیر."
مدل: نتیجه واقعی = ۱۲۱۷۲۲۱۵
```
اینجوری **احتمال خطا** خیلی کمتر می‌شه.

---

<div align="center">

## ۵. به‌روزرسانی دوره‌ای (Regular Fine-Tuning) 🔄
</div>

- **انتشار نسخه‌های جدید** مدل با داده‌های تازه یا اصلاح‌شده.  
- **رفع باگ‌های قبلی** و **کاستن از تعصب** از طریق آموزش مجدد.

**مثال عملی:**  
اگه مدل تا سال ۲۰۲۱ آموزش دیده، داده‌های **۲۰۲۲ و ۲۰۲۳** رو هم بهش اضافه کنیم تا **رویدادهای جدید** رو بدونه.

---

<div align="center">

## ۶. درخواست Self-Evaluation از خود مدل 🤔
</div>

- گاهی وقت‌ها از مدل بخوایم **جوابش رو نقد کنه**.  
- بپرسیم: «آیا ممکنه اشتباه باشی؟» یا «کدوم بخش از جوابت رو بهتر می‌تونی توضیح بدی؟»

**مثال عملی:**  
```
پرامپت:
"لطفاً پاسخ خودت در مورد نحوه کار موتور ماشین رو بازبینی کن. آیا جایی رو مبهم توضیح دادی؟"
مدل (ممکنه بگه):
"بله، قسمت مربوط به سیستم انتقال قدرت رو کامل توضیح ندادم."
```
این کار باعث می‌شه **خود مدل** هوشیارتر بشه و جواب دقیق‌تری ارائه بده.

---

<div align="center">

## ۷. خلاصه‌سازی متناوب و مدیریت حافظه (Context Management) 🗂️
</div>

- **تعداد کاراکترها** در حافظه موقت مدل محدوده.  
- برای مکالمه‌ی طولانی، از مدل بخوایم **خلاصه** بسازه تا **نکات کلیدی** فراموش نشه.

**مثال عملی:**  
```
پرامپت:
"لطفاً خلاصه ۵۰ کلمه‌ای از صحبت‌های قبلی‌مون رو بگو تا بتونی با همین خلاصه ادامه بدی."
```
اینطوری مدل **تمرکز** بیشتری رو اطلاعات مهم داره و دچار **فراموشی** نمی‌شه.

---

<div align="center">

## جمع‌بندی ✨

</div>

مشکلاتی مثل **نبود منابع، تعصبات، توهمات، خطاهای ریاضی، هک پرامپت** و غیره نشون می‌ده که هرچند LLMها بسیار توانمند هستن، اما **مطلقاً بی‌نقص نیستن**. برای افزایش **دقت و امنیت**:

1. **پرامپت‌نویسی هوشمند** 📝 (Chain of Thought، Role Prompting، Few-Shot)  
2. **نظارت و سیاست‌گذاری** 🚦 (Moderation، فیلتر محتوا)  
3. **فکت‌چک خارجی** 🔍 (اتصال به پایگاه داده یا جست‌وجو)  
4. **ابزارهای تخصصی** 🛠️ (ماشین حساب، سرویس‌های ترجمه...)  
5. **به‌روزرسانی مداوم** 🔄 (Fine-tuning منظم)  
6. **درخواست خودارزیابی** 🤔 از خود مدل  
7. **خلاصه‌سازی متناوب** 🗂️ در مکالمه‌های طولانی  


<br>

---

<br>

<div align="center">

# یک نگاه کوتاه به فاین‌تیون کردن و RAG (بازیابی همراه با تولید) 📚

</div>

برای **بهبود عملکرد مدل‌های زبانی (LLM)** می‌تونیم از دو رویکرد استفاده کنیم:  
1. **فاین‌تیون کردن (Fine-Tuning)**  
2. **بازیابی همراه با تولید (RAG - Retrieval-Augmented Generation)**  

این دو روش **مزایا** و **محدودیت**‌های خودشون رو دارن، و انتخاب بینشون به **نوع کاربرد**، **منابع** و **نیاز** شما بستگی داره.

---

<br>

<div align="center"> 

## فاین‌تیون کردن یعنی چی؟ 🤔
</div>

**فاین‌تیون (Fine-Tuning)** یعنی شما یه مدل زبانی که از قبل آموزش دیده رو با **داده‌های خاص** دوباره آموزش می‌دین تا توی **حوزه یا وظیفه‌ای مشخص** عملکرد بهتری داشته باشه.  

- **مثال:** اگه یه مدل عمومی دارین و می‌خواین برای **تحلیل احساسات** در شبکه‌های اجتماعی دقیق‌تر بشه، می‌تونین با داده‌های برچسب‌خورده‌ی احساسی (مثبت، منفی، خنثی) مدل رو دوباره آموزش بدین.

### مزایای فاین‌تیون کردن

1. **دقت و تخصص بالاتر**: مدل روی وظیفه یا حوزه‌ی خاصی **متمرکز** می‌شه و **خطای کمتری** داره.  
2. **یکپارچگی در پاسخ**: بعد از آموزش، **آفلاین** هم می‌تونه کار کنه (بسته به معماری).  
3. **دسترسی سریع به پاسخ**: اگه داده‌ها رو از قبل باهاش تمرین دادین، لازم نیست برای هر سؤال به دیتابیس خارجی وصل بشین.

#### معایب فاین‌تیون کردن

1. **نیاز به داده‌های باکیفیت**: اگه داده کم یا نامناسب باشه، ممکنه نتیجه‌ی خوبی نده.  
2. **هزینه و منابع محاسباتی**: بسته به بزرگی مدل، **آموزش دوباره** می‌تونه زمان‌بر و گرون باشه.  
3. **به‌روز نبودن**: اگه داده‌های جدید وارد بشن، باید **دوباره مدل رو آموزش** بدین تا از داده‌های تازه مطلع بشه.

---

<br>

<div align="center">

## بازیابی همراه با تولید (RAG) چیه؟ 🌐
</div>

در واقع **RAG** یک روش ترکیبیه که به مدل زبانی **اجازه می‌ده** قبل از تولید پاسخ، **به یه پایگاه داده یا منبع اطلاعاتی** دسترسی پیدا کنه. به‌جای اینکه مدل همیشه همه چیز رو از **حافظه داخلی** خودش بدونه، از **اطلاعات بیرونی** استفاده می‌کنه.

- **مثال:** اگه بخواین جواب‌های به‌روز درباره قیمت ارز دیجیتال داشته باشین، مدل می‌تونه **هردفعه** از منبعی آنلاین مثل **API قیمت‌ها** کمک بگیره و بعد **پاسخی تولید کنه** که شامل اطلاعات جدید باشه.

### مزایای RAG

1. **به‌روزبودن**: مدل می‌تونه از **جدیدترین اطلاعات** استفاده کنه.  
2. **کاهش حجم آموزش**: لازم نیست مدل **همه‌ی دانسته‌ها** رو داخلی داشته باشه؛ می‌تونه به **منابع بیرونی** وصل بشه.  
3. **انعطاف‌پذیری**: اگه نیاز به حوزه‌های مختلف داشته باشین، می‌تونین **از دیتابیس‌های متفاوت** استفاده کنین.

### معایب RAG

1. **پیچیدگی زیرساخت**: نیاز به مدیریت یه **دیتابیس خارجی** دارین که مدل بتونه ازش اطلاعات بگیره.  
2. **نیاز به اتصال پایدار**: اگه مدل به منبع دسترسی نداشته باشه، **یا پاسخ اشتباه می‌ده** یا ناقص می‌مونه.  
3. **دقیق نبودن داده بیرونی**: اگه **دیتابیس** یا **موتور جست‌وجو** مورد استفاده **غیرقابل اعتماد** باشه، کیفیت جواب افت می‌کنه.

---

<br>

<div align="center">

### آیا دقت RAG از فاین‌تیون کمتره؟
</div>

اغلب **RAG** رو روشی با **انعطاف بیشتر** می‌دونن، ولی الزماً به معنی **دقت کمتر** نیست.  
- اگه **دیتابیس** به‌درستی سازماندهی و برچسب‌گذاری شده باشه و **جست‌وجوی** خوبی هم داشته باشیم، ممکنه **جواب دقیق‌تری** بده چون **منبع مستقیم** رو جست‌وجو می‌کنه.  
- اما اگه پایگاه داده **نامعتبر** باشه یا موتور جست‌وجو **ضعیف** کار کنه، مدل پاسخ‌های گمراه‌کننده می‌ده.

---

<br>

<div align="center">

## تفاوت‌ها در یک نگاه ⚖️
</div>

| ویژگی                       | فاین‌تیون (Fine-Tuning) | RAG (بازیابی + تولید)     |
|----------------------------|------------------------|----------------------------|
| **روش یادگیری**            | دوباره آموزش با داده خاص | دسترسی به پایگاه داده برای اطلاعات تازه |
| **نیاز به داده آموزشی**    | بله، برای هر آپدیت، آموزش مجدد | خیر، با دیتابیس بیرونی به‌روز می‌مونه |
| **هزینه و منابع**          | ممکنه بالا باشه (GPU و زمان) | کمتره اما به زیرساخت دیتابیس نیاز داره |
| **به‌روز بودن**            | بعد از آموزش، ثابت می‌مونه | امکان دسترسی به اطلاعات جدید |
| **دقت در حوزه خاص**        | معمولاً خیلی بالا (اگه داده خوب باشه) | بستگی به کیفیت دیتابیس و روش جست‌وجو داره |
| **مثال کاربردی**           | آموزش برای تشخیص احساسات متون | پاسخ به سوالات مرتبط با قیمت ارز جدید |

---

<br>

<div align="center">

### کدوم روش برای چه کاری مناسبه؟ 🤔
</div>

- **اگه نیاز به یه مدل کاملاً تخصصی و دقیق دارین** (مثل تشخیص بیماری از روی متن پزشکی) و به روز بودن داده‌ها **کم اهمیت**ه یا می‌تونین هر چند وقت یه بار مدل رو آپدیت کنین، **فاین‌تیون** روش خوبیه.
- **اگه نیاز به اطلاعات به‌روز دارین** (مثل اخبار، قیمت‌ها، یا دانشی که مرتبا تغییر می‌کنه) و نمی‌خواین مدام مدل رو آموزش بدین، **RAG** انتخاب بهتریه.
- در برخی موارد، **ترکیبی** از هر دو می‌تونه بهترین نتیجه رو بده؛ مثلاً مدل رو تا حدی **فاین‌تیون** کنین تا «زبان تخصصی» اون حوزه رو بفهمه، و در عین حال **RAG** رو اضافه کنین تا از اطلاعات جدید استفاده کنه.

---

<br>

<div align="center">

## جمع‌بندی کلی 🏁
</div>

- **فاین‌تیون کردن**: مدل رو دقیق‌تر و تخصصی‌تر می‌کنه، اما **هزینه‌ی آموزش** بالاست و برای اطلاعات تازه باید دوباره آموزش ببینه.  
- **RAG**: مدل رو قادر می‌کنه **از پایگاه داده‌های خارجی** کمک بگیره و جوابش رو آپدیت کنه، ولی **نیازمند زیرساخت و مدیریت** دیتابیسه.  

انتخاب **کاملاً بستگی** به **هدف و منابع** شما داره: اگه **ثبات و دقت در یه دامنه‌ی محدود** می‌خواین، فاین‌تیون. اگه **انعطاف و اطلاعات به‌روز** می‌خواین، RAG.  


<br>

---

<br>

<div align="center">

# دو روش ساخت پرامپت (با کمک ابزارها) 🚀

</div>

این بخش دوتا روش ساده و کاربردی معرفی می‌کنه که می‌تونی باهاشون پرامپت‌های بهتری بسازی یا اونایی که داری رو بهبود بدی.

---

<br>

<div align="center">

## ۱. استفاده از پرامپت‌های پرامپت‌ساز 🛠️

</div>

توی این روش، از خود مدل می‌خوایم نقش یه «پرامپت‌نویس حرفه‌ای» رو بازی کنه و براساس نیاز ما، یه پرامپت کامل و باکیفیت تولید کنه.

**چطوری کار می‌کنه؟**  
1. پرامپت زیر رو به مدل می‌دی.  
2. موضوع یا کاری که براش پرامپت می‌خوای رو مشخص می‌کنی.  
3. مدل یه پرامپت ساختاریافته برای همون موضوع تولید می‌کنه.

---

### پرامپت پیشنهادی برای شروع ✏️


<div align="left">

```
You are an expert prompt engineer. Your objective is to create a comprehensive, high-quality system prompt based on the user's request. Use precise and professional language, ensuring the prompt thoroughly addresses each of the following sections:
You are an expert prompt engineer. Your objective is to create a comprehensive, high-quality system prompt based on the user’s request. Use precise and professional language, ensuring the prompt thoroughly addresses each of the following sections:

---

### 1. System Prompt
- **Objective**: Clearly state the AI’s primary goal.  
- **Role Definition**: Define the AI’s role with precision, focusing on the core functionality the user needs.

### 2. Instructions
- **Task Breakdown**: Break down complex actions into sequential, easy-to-follow steps.  
- **Actionable Language**: Provide explicit directives to avoid ambiguity.  
- **Coverage**: Address every necessary aspect of the functionality or process requested.

### 3. Constraints
- **Boundaries**: Specify what the AI can and cannot do (e.g., scope of tasks or compliance requirements).  
- **Ethical Considerations**: Ensure adherence to relevant standards, regulations, and responsible practices.

### 4. Output Format
- **Structure**: Indicate how the AI’s final answer should be organized (e.g., headings, bullet points).  
- **Formatting Requirements**: Detail any specific text styling or layout guidelines (e.g., code blocks, markdown).  
- **Level of Detail**: Clarify whether the output should be concise, moderately detailed, or exhaustive.

### 5. Examples
- **Sample Inputs**: Provide illustrative prompts or scenarios that the AI could receive.  
- **Sample Outputs**: Show how the AI should respond to these inputs, adhering to the established format and constraints.
```

</div>




---

<br>

<div align="center">

## ۲. استفاده از سایت پرامپت‌ساز آنلاین 🌐

</div>

اگه ترجیح می‌دی به‌جای مدل، یه ابزار برات پرامپت بسازه، می‌تونی از سایت [**prompts.maux.site**](https://prompts.maux.site) استفاده کنی. این ابزار رایگانه و توسط یکی از بچه‌های ایرانی ساخته شده. سورسش هم اینجاست:  

[github.com/MauxPlatform/PromptKadeh](https://github.com/MauxPlatform/PromptKadeh)



**چطوری کار می‌کنه؟**  
1. موضوعت رو وارد می‌کنی.  
2. سایت برات پرامپت می‌سازه.  
3. با چند مثال مختلف، این پرامپت‌ها رو تست می‌کنه.  

<br>


**نکته مهم:**  
اگه با محدودیت رایگان سایت روبه‌رو شدی، می‌تونی از یه توکن رایگان استفاده کنی.  
فقط کافیه بری به [aistudio.google.com](https://aistudio.google.com) و با اکانت گوگل یه **توکن رایگان** بگیری.  
تعداد پرامپت‌هایی که باهاش می‌تونی بزنی کمه، ولی برای تست و ساخت چند پرامپت **کاملاً جواب می‌ده**.




<br>


---

<br>

<div align="center">

# دسترسی رایگان به API برای استفاده از LLMها 🌐

</div>

اگه نمی‌خوای از اول هزینه کنی یا دسترسی به APIهای پولی مثل OpenAI نداری، اینجا چند تا راه ساده و رایگان هست که باهاش می‌تونی مدل‌های زبانی قوی رو تست و استفاده کنی. این روش‌ها هم برای تمرین خوبن، هم برای شروع کار واقعی.

---

<br>

<div align="center">

## ۱. استفاده از سرویس‌های آنلاین 🌍

</div>

چند تا پلتفرم هستن که خیلی راحت می‌تونی با ساختن یه حساب، ازشون مدل بگیری و استفاده کنی:

### سرویس **[Google AI Studio](https://aistudio.google.com)**  
  با این ابزار می‌تونی خیلی راحت مدل‌های گوگل (مثل gemini) رو امتحان کنی. گوگل یه مقدار توکن رایگان بهت می‌ده، ولی استفاده ازش محدوده. با این حال، برای تمرین و تست، انتخاب خوبیه.

### سرویس **[DeepInfra](https://deepinfra.com)**  
  این سایت بهت اجازه می‌ده از مدل‌های اپن‌سورس استفاده کنی. ثبت‌نامش راحته، بعدش یه API Key می‌گیری و می‌تونی به مدل‌های مختلف وصل شی. مدل‌هایی مثل llama یا mistral رو راحت می‌تونی ازش اجرا بگیری.

### سرویس **[OpenRouter](https://openrouter.ai)**  
  اینم یک سرویس جالبیه که درخواستت رو می‌فرسته به مدلی که فکر می‌کنه بهتر جواب می‌ده(قیمت رو هم در نظر میگیره). یه مقدار استفاده‌ی رایگان داره، ولی اگه خواستی بیشتر استفاده کنی، باید حساب شارژ کنی. خوبی بزرگش اینه که پرداخت با کریپتو هم داره، که برای خیلی از کاربرا (مخصوصاً ایرانیا) دردسر رو کمتر می‌کنه.

---

<br>

<div align="center">

## ۲. اجرا کردن مدل روی لپ‌تاپ با Ollama 🖥️

</div>

اگه می‌خوای مدل رو مستقیم روی سیستم خودت اجرا کنی، Ollama انتخاب خیلی خوبیه. نیاز به اینترنت دائم نداره، و مدل رو روی سیستم خودت اجرا می‌کنی.

مثلاً برای اجرا کردن یه مدل، فقط کافیه این دستورها رو بزنی:

```
ollama pull gemma:2b
ollama run gemma:2b
```

اگه مدل رو نداری، خودش برات دانلودش می‌کنه.


---

<br>

<div align="center">

## ۳. اجرا کردن مدل با ظاهر گرافیکی توی LM Studio 🎛️

</div>

LM Studio هم مثل Ollama مدل رو روی سیستم خودت اجرا می‌کنه، با این تفاوت که یه رابط گرافیکی خوشگل داره. یعنی لازم نیست با خط فرمان کار کنی. خیلی راحت مدل رو انتخاب می‌کنی و توی یه پنجره‌ی تمیز باهاش چت می‌کنی.

یه نکته‌ی خوب دیگه‌اش اینه که API هم می‌ده. یعنی می‌تونی مدل اجرا شده رو از طریق API توی پروژه‌هات استفاده کنی.

برای دیدن لیست مدل‌هاش، برو به:  
[lmstudio.ai/models](https://lmstudio.ai/models)


<br>

---

<br>

<div align="center">

# 🤝 کمک کردن به این پروژه!

</div>

<div align="right">

- این پروژه رو fork کنید و به زبون‌های برنامه نویسی دیگه توسعه بدید!
- این ریپو رو برای دوستاتون بفرستید!
- اشتباهاتی که وجود داره رو با issue و یا pull request فیکس کنید!
- مثال‌ها رو بهبود ببخشید و با issue و یا pull request به اشتراک بسازید!
- اگه تجربه عملی ای با هر الگو دارید اون رو به مثال ها اضافه کنید!
- با ⭐ به پروژه از من و این ریپو حمایت کنید و باعث دیده شدنش بشید!

</div>

</div>
