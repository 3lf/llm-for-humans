<div dir="rtl">

<div align="center">
<img src="images/poster.jpg" alt="LLM for Humans Poster">
</div>


---

<br>


<div align="center">

# مقدمه 📚

</div>


دو سال پیش که دیدم منبع فارسی درست‌حسابی برای یادگیری دیزاین پترن‌ها کمه، یه **ریپازیتوری** ساختم به اسم [دیزاین پترن به زبان آدمیزاد](https://github.com/3lf/design-patterns-for-humans).  استقبال خوبی هم ازش شد.

حالا داستان **مدل‌های زبانی بزرگ (LLM ها)** هم همینه. این روزا اسم ChatGPT و Gemini و بقیه مدل‌ها همه جا هست و خیلی‌ها هم دارن ازشون استفاده می‌کنن. ولی قضیه اینه که چطور می‌شه **بهتر** ازشون کار کشید؟ چطور باید باهاشون حرف زد (یا به قول فنی‌ها، **پرامپت نوشت**) که دقیقاً همون چیزی که می‌خوایم رو بهمون بدن؟

دیدم اینجا هم جای یه راهنمای **ساده و خودمونی** خالیه. برای همین این ریپو رو درست کردم تا مثل دفعه قبل، سعی کنم روش‌های کار با LLM ها رو **روون و راحت** توضیح بدم. از اینکه چطور یه **پرامپت خوب** بنویسیم شروع می‌کنیم و می‌ریم سراغ کلی **نکته و ترفند کاربردی** که می‌تونه کمک کنه نتیجه بهتری از این مدل‌ها بگیرید.

هدف اینه که چه برنامه‌نویس باشید، چه محتوا تولید کنید یا فقط کنجکاو باشید، بتونید راحت‌تر با این ابزارهای جدید کار کنید و ازشون به نفع خودتون استفاده کنید.

---

<br>

# فهرست مطالب ✨

*   **📚 مقدمه** [🔗](#user-content-مقدمه-)
*   **🤖 مدل‌های زبانی بزرگ (LLM)** [🔗](#user-content-مدلهای-زبانی-بزرگ-llm-)
*   **✍️ پرامپت‌نویسی** [🔗](#user-content-پرامپتنویسی-️)
    *   چطور یه پرامپت خوب بنویسیم؟ [🔗](#user-content-چطور-یه-پرامپت-خوب-بنویسیم-)
    *   نمونه‌ای از یک پرامپت خوب [🔗](#user-content-نمونهای-از-یک-پرامپت-خوب-)
*   **🚀 چطور یه پرامپت قوی‌تر بنویسیم؟** [🔗](#user-content-چطور-یه-پرامپت-قویتر-بنویسیم-)
    *   ۱. استفاده از مرزها [🔗](#user-content-1-استفاده-از-مرزها-برای-تفکیک-دادهها-از-پرامپت-️)
    *   ۲. خروجی ساختاریافته [🔗](#user-content-2-درخواست-خروجی-ساختاریافته-️)
    *   ۳. تغییر لحن خروجی [🔗](#user-content-3-اضافه-کردن-اطلاعات-سبک-برای-تغییر-لحن-خروجی-)
    *   ۴. بررسی شرایط [🔗](#user-content-4-دادن-شرایط-به-مدل-و-درخواست-بررسی-آنها-)
    *   ۵. مثال‌های موفق [🔗](#user-content-5-دادن-مثالهای-موفق-از-انجام-وظایف-و-سپس-درخواست-)
    *   ۶. حل مسئله قبل از جواب [🔗](#user-content-6-درخواست-از-مدل-برای-حل-مسئله-قبل-از-دادن-جواب-)
    *   ۷. تکرار و بهبود [🔗](#user-content-7-تکرار-و-بهبود-پرامپتها-)
    *   جمع‌بندی نهایی [🔗](#user-content-جمعبندی-نهایی-)
*   **⚙️ پارامترهای مهم LLM** [🔗](#user-content-پارامترهای-مهم-در-کار-با-llmها-️)
    *   مقدار Temperature (خلاقیت/دقت) [🔗](#user-content-مقدار-temperature-دمای-خلاقیت--دقت-️)
    *   مقدار Top-p (نمونه‌برداری هسته‌ای) [🔗](#user-content-مقدار-top-p-نمونهبرداری-هستهای--nucleus-sampling-)
    *   مقدار Frequency Penalty (جریمه تکرار کلمه) [🔗](#user-content-مقدار-frequency-penalty-جریمه-تکرار-کلمه-)
    *   مقدار Presence Penalty (جریمه تکرار موضوع) [🔗](#user-content-مقدار-presence-penalty-جریمه-تکرار-موضوعتوکن-)
    *   مقدار Top-k (گزینش از k تای برتر) [🔗](#user-content-مقدار-top-k-گزینش-از-k-تای-برتر-)
    *   خلاصه تفاوت پارامترها [🔗](#user-content--خلاصه-تفاوت-پارامترها-به-زبان-ساده)
    *   پیشنهاد کاربردی [🔗](#user-content-یه-پیشنهاد-کاربردی-در-آخر)
*   **💡 System Prompt** [🔗](#user-content-system-prompt-)
    *   تعریف System Prompt [🔗](#user-content-تعریف-system-prompt)
    *   چطور کار می‌کنه؟ [🔗](#user-content-چطور-کار-میکنه-️)
    *   مثال کاربردی [🔗](#user-content-مثال-کاربردی-)
    *   چرا مهمه؟ [🔗](#user-content-چرا-system-prompt-مهمه-)
*   **📜 تکنیک‌های پرامپت‌نویسی** [🔗](#user-content-تکنیکهای-پرامپتنویسی-)
    *   ۱. نقش‌دهی (Role Prompting) [🔗](#user-content-۱-نقشدهی-role-prompting-)
    *   ۲. ارائه چند مثال (Few-Shot) [🔗](#user-content-۲-ارائه-چند-مثال-few-shot-prompting-)
    *   ۳. زنجیره تفکر (CoT) [🔗](#user-content-۳-زنجیره-تفکر-chain-of-thought-prompting---cot-)
    *   ۴. درخت تفکر (ToT) [🔗](#user-content-۴-درخت-تفکر-tree-of-thoughts---tot-)
    *   ۵. استدلال و عمل (ReAct) [🔗](#user-content-۵-استدلال-و-عمل-react---reasoning-and-acting-️)
    *   ۶. خود-سازگاری (Self-Consistency) [🔗](#user-content-۶-خود-سازگاری-self-consistency-prompting-)
    *   نکات تکمیلی [🔗](#user-content-نکات-تکمیلی-و-پایانی-)
*   **⚠️ مشکلات معروف LLMها** [🔗](#user-content-مشکلات-معروف-llmها-️)
    *   ۱. عدم ارائه منابع [🔗](#user-content-۱-ناتوانی-در-ارائه-منابع-معتبر-citing-sources-)
    *   ۲. تعصب در پاسخ‌ها [🔗](#user-content-۲-تعصب-در-پاسخها-bias-)
    *   ۳. توهمات (Hallucinations) [🔗](#user-content-۳-توهمات-یا-تولید-اطلاعات-ساختگی-hallucinations-)
    *   ۴. خطای محاسبات [🔗](#user-content-۴-اشتباه-در-محاسبات-ریاضی-math-errors-)
    *   ۵. هک پرامپت [🔗](#user-content-۵-هک-پرامپت-prompt-hacking-️)
    *   ۶. محدودیت حافظه (Context Window) [🔗](#user-content-۶-محدودیتهای-پنجره-محتوایی-context-window-)
    *   ۷. دانش قدیمی [🔗](#user-content-۷-دانش-قدیمی-یا-محدودیت-زمانی-outdated-knowledge-)
    *   ۸. عدم درک عمیق [🔗](#user-content-۸-عدم-درک-مفاهیم-عمیق-یا-حالات-احساسی-️)
*   **🛡️ افزایش دقت و امنیت LLM** [🔗](#user-content-چطور-دقت-و-امنیت-llm-رو-بالاتر-ببریم-️)
    *   ۱. پرامپت‌نویسی هوشمند [🔗](#user-content-۱-پرامپتنویسی-هوشمند-smart-prompting-)
    *   ۲. نظارت بر خروجی‌ها [🔗](#user-content-۲-نظارت-بر-خروجیها-moderation--policy-)
    *   ۳. فکت‌چک بیرونی [🔗](#user-content-۳-فکتچک-بیرونی-external-fact-checking-)
    *   ۴. ترکیب با ابزارها [🔗](#user-content-۴-ترکیب-llm-با-ابزارهای-تخصصی-tool-integration-️)
    *   ۵. به‌روزرسانی دوره‌ای [🔗](#user-content-۵-بهروزرسانی-دورهای-regular-fine-tuning-)
    *   ۶. درخواست خودارزیابی [🔗](#user-content-۶-درخواست-self-evaluation-از-خود-مدل-)
    *   ۷. مدیریت حافظه [🔗](#user-content-۷-خلاصهسازی-متناوب-و-مدیریت-حافظه-context-management-️)
    *   جمع‌بندی [🔗](#user-content-جمعبندی-)
*   **🔄 فاین‌تیون و RAG** [🔗](#user-content-یک-نگاه-کوتاه-به-فاینتیون-کردن-و-rag-بازیابی-همراه-با-تولید-) 
    *   فاین‌تیون کردن [🔗](#user-content-فاینتیون-کردن-یعنی-چی-)
    *   RAG (بازیابی + تولید) [🔗](#user-content-بازیابی-همراه-با-تولید-rag-چیه-)
    *   تفاوت‌ها در یک نگاه [🔗](#user-content-تفاوتها-در-یک-نگاه-️)
    *   جمع‌بندی کلی [🔗](#user-content-جمعبندی-کلی-)
*   **🛠️ دو روش ساخت پرامپت** [🔗](#user-content-دو-روش-ساخت-پرامپت-با-کمک-ابزارها-) 
    *   ۱. استفاده از پرامپت‌های پرامپت‌ساز [🔗](#user-content-۱-استفاده-از-پرامپتهای-پرامپتساز-️)
    *   ۲. استفاده از سایت پرامپت‌ساز آنلاین [🔗](#user-content-۲-استفاده-از-سایت-پرامپتساز-آنلاین-)
*   **🌐 دسترسی رایگان به API** [🔗](#user-content-دسترسی-رایگان-به-api-برای-استفاده-از-llmها-) 
    *   ۱. سرویس‌های آنلاین [🔗](#user-content-۱-استفاده-از-سرویسهای-آنلاین-)
    *   ۲. اجرا روی لپ‌تاپ (Ollama) [🔗](#user-content-۲-اجرا-کردن-مدل-روی-لپتاپ-با-ollama-️)
    *   ۳. اجرا با رابط گرافیکی (LM Studio) [🔗](#user-content-۳-اجرا-کردن-مدل-با-ظاهر-گرافیکی-توی-lm-studio-️)
*   **🤝 کمک به پروژه** [🔗](#user-content--کمک-کردن-به-این-پروژه)

---

<div align="center">

# مدل‌های زبانی بزرگ (LLM) چی هستن اصلاً؟ 🤖

</div>

خب، بریم سراغ اصل مطلب: این **LLM ها** (مخفف **Large Language Model**) که این‌قدر اسمشون رو می‌شنویم، چی هستن؟

خیلی ساده بخوایم بگیم، LLM یه جور **هوش مصنوعی خیلی باهوشه** که روی **حجم وحشتناکی** از متن، کد، و انواع داده‌های دیگه (مثل ویکی‌پدیا، کتاب‌ها، کلی وب‌سایت و...) آموزش دیده. هدف این آموزش این بوده که بتونه زبان آدم‌ها (و حتی زبان‌های برنامه‌نویسی!) رو **بفهمه** و خودش هم متن، کد، یا حتی چیزای دیگه **تولید کنه**.

**خب حالا این LLM ها دقیقاً چه کارایی ازشون برمیاد؟**
کارهای خیلی زیادی می‌تونن بکنن، مثلاً:

*   **متن بنویسن** (مثل مقاله، ایمیل، داستان)، یا متن‌های طولانی رو **خلاصه کنن**.
*   به **سوال‌هاتون** (تقریباً در هر زمینه‌ای) جواب بدن.
*   متن‌ها رو به زبان‌های مختلف **ترجمه** کنن.
*   مثل یه آدم باهاتون **چت کنن** و گفتگو رو ادامه بدن.
*   **داده‌ها رو تحلیل کنن** و الگوهای داخلشون رو پیدا کنن.
*   براتون **کد بنویسن**، کدتون رو تکمیل کنن، یا اشکالاتش رو پیدا کنن (دیباگ کنن).
*   و حتی **عکس و صدا** هم بسازن!

خلاصه کلام: **LLM یه سیستمه که ورودی شما رو می‌گیره، پردازش می‌کنه و یه خروجی مرتبط و (معمولاً) مفید تحویل می‌ده.**

نکته کلیدی اینجاست: **کیفیت خروجی خیلی به کیفیت ورودی (همون پرامپت) بستگی داره.** یعنی اگه می‌خوای بهترین جواب رو بگیری، باید یاد بگیری چطور **درست و حسابی پرامپت بنویسی** و خواسته‌ت رو واضح به مدل بگی. این همون مهارتیه که قراره توی بخش‌های بعدی بیشتر در موردش حرف بزنیم.

<br>

---

<br>

<div align="center">

# پرامپت‌نویسی: یعنی چی؟ چطور به LLM دستور بدیم؟ ✍️

</div>

پرامپت در واقع همون **دستور یا سوالیه** که شما به LLM می‌دین. مثل اینکه بخوای به یه دستیار خیلی باهوش بگی دقیقاً چی کار کنه یا چه اطلاعاتی بهت بده. این دستور می‌تونه یه سوال ساده باشه، یه درخواست برای نوشتن متن، خلاصه‌کردن یه مطلب، یا هر چیز دیگه‌ای.

یه قانون خیلی ساده ولی مهم اینجا وجود داره: **هر چی پرامپت شما واضح‌تر، دقیق‌تر و حساب‌شده‌تر باشه، جوابی هم که از LLM می‌گیرید بهتر و به درد بخورتره.** مثل این می‌مونه که آدرس دقیق بدی تا به مقصد برسی؛ اگه آدرس رو کلی و نامفهوم بدی، معلوم نیست کجا سر در میاری!

---

<br>

<div align="center">

## خب، چطور یه پرامپت خوب و کارراه‌انداز بنویسیم؟ 🏗

</div>

برای اینکه LLM بهترین جواب ممکن رو بهتون بده، سعی کنید پرامپت‌هاتون این ویژگی‌ها رو داشته باشن:

*   **صاف و پوست‌کنده منظورتون رو بگید:** از کلی‌گویی و حرفای مبهم دوری کنید. دقیقاً بگید چی می‌خواید.
*   **شرایط و چارچوب رو مشخص کنید:** به مدل بگید جواب رو تو چه قالبی می‌خواید؟ (مثلاً لیست باشه، جدول باشه، کد باشه؟). لحنش چطور باشه؟ (رسمی، دوستانه، طنز؟). محدودیتی داره؟ (مثلاً طول جواب بیشتر از ۱۰۰ کلمه نباشه).
*   **اگه لازمه، جزئیات یا مثال بزنید:** گاهی یه مثال کوچیک می‌تونه به مدل کمک کنه دقیقاً بفهمه دنبال چی هستید و کارتون رو خیلی بهتر راه بندازه.
*   **ساده و سرراست بنویسید:** جمله‌های پیچیده و تودرتو ممکنه مدل رو گیج کنه. سعی کنید روان و مستقیم حرف بزنید.

---

<br>

<div align="center">

## یه مثال ساده از پرامپت‌نویسی 🌍

</div>

بذارید با یه مثال ببینیم منظور چیه:

**فرض کنید می‌خوایم یه ایمیل رسمی برای درخواست مرخصی بنویسیم.**

**پرامپت ما می‌تونه این باشه:**
`یه ایمیل رسمی و مودبانه به مدیرم بنویس برای درخواست مرخصی ۳ روزه. دلیل مرخصی رو هم توی ایمیل بیار (مثلاً: به دلیل مسائل شخصی).`

**جواب احتمالی LLM:**

```text
موضوع: درخواست مرخصی

جناب آقای/سرکار خانم [نام مدیر]،
با سلام و احترام،

احتراماً به استحضار می‌رساند، اینجانب [نام شما] قصد دارم از تاریخ [تاریخ شروع] به مدت سه روز تا تاریخ [تاریخ پایان] به دلیل مسائل شخصی از مرخصی استحقاقی خود استفاده نمایم.

پیشاپیش از حسن توجه و موافقت حضرتعالی کمال تشکر را دارم.

با احترام،
[نام شما]
[سمت شما (اختیاری)]
[تاریخ]
```

ببینید چطور با یه پرامپت نسبتاً واضح، یه خروجی کاملاً مناسب و کاربردی گرفتیم. توی بخش‌های بعدی، تکنیک‌های پیشرفته‌تری برای نوشتن پرامپت‌های قوی‌تر رو یاد می‌گیریم.

<br>

---

<br>

<div align="center">

# چطور پرامپت‌های بهتری بنویسیم؟ (تکنیک‌های پیشرفته‌تر) 🚀

</div>

خب، حالا که اصول اولیه پرامپت‌نویسی رو گفتیم، وقتشه یه کم حرفه‌ای‌تر بشیم! 😎
یادتونه گفتیم هرچی پرامپت دقیق‌تر باشه، جواب بهتری می‌گیریم؟ این چند تا تکنیک بهتون کمک می‌کنه پرامپت‌هاتون رو **واضح‌تر، دقیق‌تر و قوی‌تر** کنید تا LLM دقیقاً همون کاری که می‌خواید رو براتون انجام بده.

---

<br>

<div align="center">

## ۱. دستور و داده رو قاطی نکن! (استفاده از جداکننده‌ها) ✂️

</div>

بعضی وقتا شما هم یه **دستور** به مدل می‌دین (مثلاً "این متنو خلاصه کن") و هم یه **تکه داده** (همون متنی که باید خلاصه بشه). اگه این دوتا رو همینجوری پشت سر هم بنویسید، مدل ممکنه قاطی کنه که کدوم دستوره و کدوم داده!

بهترین کار اینه که با یه **جداکننده واضح**، این دو بخش رو از هم سوا کنید. رایج‌ترین و ساده‌ترین راه، استفاده از سه تا بک‌تیک (``` ` ```) هست:

**مثال:** فرض کنید می‌خواید یه پاراگراف رو خلاصه کنید.

```markdown
لطفاً پاراگراف زیر رو در یک جمله خلاصه کن:

‌```
مدل‌های زبانی بزرگ یا LLMها، نوعی هوش مصنوعی هستند که بر روی حجم عظیمی از داده‌های متنی آموزش دیده‌اند. آن‌ها می‌توانند زبان انسان را درک کرده، تولید کنند و وظایف مختلفی مانند ترجمه، خلاصه‌سازی و پاسخ به سوالات را انجام دهند. توانایی آن‌ها در درک مفاهیم پیچیده و تولید متن منسجم، آن‌ها را به ابزاری قدرتمند در حوزه‌های مختلف تبدیل کرده است.
```‌

```

**روش‌های دیگه هم هست؟**
آره، می‌تونید از جداکننده‌های دیگه مثل سه تا هشتگ (`###`) یا حتی تگ‌های ساده XML/HTML (مثل `<text_to_summarize> ... </text_to_summarize>`) هم استفاده کنید. مهم اینه که یه مرز مشخص بین دستور و داده‌تون بذارید.

**چرا این کار مهمه؟**
چون به مدل کمک می‌کنه **دقیقاً بفهمه** قراره روی کدوم قسمت از متن کار کنه و چه کاری رو انجام بده. اینطوری احتمال خطا و کج‌فهمی خیلی کمتر می‌شه.

---

<br>

<div align="center">

## ۲. خروجی رو تو قالب دلخواهت بگیر (JSON، لیست، جدول و...) 🗂️

</div>

گاهی وقتا جواب مدل رو نمی‌خواید همینجوری یه متن ساده باشه. مثلاً اگه برنامه‌نویس باشید، شاید لازم داشته باشید جواب رو تو فرمت **JSON** بگیرید تا راحت تو کدتون ازش استفاده کنید. یا شاید بخواید جواب به صورت یه **لیست شماره‌دار** یا یه **جدول** باشه.

**خیلی راحت می‌تونید تو پرامپت از مدل بخواید خروجی رو تو فرمت خاصی بهتون بده.**

**مثال: گرفتن خروجی JSON**

```markdown
اطلاعات کتاب زیر رو به صورت یک آبجکت JSON با کلیدهای `title`, `author`, و `year` بهم بده:

```‌
نام کتاب: بوف کور
نویسنده: صادق هدایت
سال انتشار: ۱۳۱۵
```‌
```

**پاسخ احتمالی مدل:**

```json
{
  "title": "بوف کور",
  "author": "صادق هدایت",
  "year": 1315
}
```

**مثال دیگه: درخواست لیست**
`مزایای اصلی یادگیری پایتون رو به صورت یه لیست شماره‌دار برام بنویس.`

**چرا این کار مفیده؟**
*   جوابی که می‌گیرید **استاندارد و قابل پیش‌بینی** می‌شه.
*   اگه قراره خروجی رو جای دیگه‌ای (مثل کد، دیتابیس، اکسل) استفاده کنید، کارتون **خیلی راحت‌تر** می‌شه.

---

<br>

<div align="center">

## ۳. به مدل بگو با چه لحنی حرف بزنه (رسمی، خودمونی، طنزآمیز؟) 🎨

</div>

یکی از قابلیت‌های باحال LLMها اینه که می‌تونن با **لحن‌ها و شخصیت‌های مختلف** براتون متن تولید کنن! فقط کافیه تو پرامپت بهش بگید چه لحنی مد نظرتونه.

**مثال: لحن دوستانه**

```markdown
با یه لحن ساده و خودمونی توضیح بده چطوری می‌تونم یه چای خوب دم کنم. انگار داری برای دوستت توضیح می‌دی.
```

**مثال: لحن رسمی**

```markdown
یک پاراگراف رسمی در مورد اهمیت حفظ حریم خصوصی در دنیای دیجیتال بنویس.
```

**مثال: لحن خاص (شخصیت‌سازی)**

```markdown
فرض کن یه دزد دریایی هستی! توضیح بده چرا پیدا کردن گنج مهمه.
```

**نتیجه چیه؟**
مدل سعی می‌کنه از کلمات و جمله‌بندی‌هایی استفاده کنه که اون **حس و حال و لحن درخواستی** شما رو منتقل کنه. این برای تولید محتوای متناسب با مخاطب یا هدف خاص، عالیه!

---

<br>

<div align="center">

## ۴. شرط بذار، بعد دستور بده! ✅

</div>

می‌تونید از LLM بخواید **اول یه سری شرایط رو چک کنه** و بعد بر اساس نتیجه اون شرایط، یه کاری رو انجام بده یا یه جوابی بده.

**مثال:** فرض کنید یه سیستم ساده برای پیشنهاد فیلم دارید.

```markdown
لطفاً بررسی کن:
اگر ژانر مورد علاقه کاربر "کمدی" است و رده‌بندی سنی فیلم "زیر ۱۸ سال" است، پیشنهاد بده فیلم "پسر دلفینی" رو ببینه.

ژانر مورد علاقه: کمدی
رده‌بندی سنی فیلم: زیر ۱۸ سال
```

**جواب احتمالی:**
`پیشنهاد می‌کنم فیلم "پسر دلفینی" رو ببینید.`

**مثال دیگه (چک کردن متن):**

```markdown
اگر متن زیر شامل کلمه "تخفیف" بود، بنویس "پیشنهاد ویژه وجود دارد!". در غیر این صورت، بنویس "پیشنهاد خاصی یافت نشد."

متن:
```‌
همین حالا ثبت نام کنید و از ۱۰ درصد تخفیف ویژه بهره‌مند شوید!
```‌
```

**جواب احتمالی:**
`پیشنهاد ویژه وجود دارد!`

**به چه دردی می‌خوره؟**
برای پیاده‌سازی **منطق‌های ساده و تصمیم‌گیری‌های شرطی** توی خود پرامپت خیلی کاربردیه و می‌تونه جواب‌ها رو هدفمندتر کنه.

---

<br>

<div align="center">

## ۵. با مثال بهش یاد بده چی می‌خوای (Few-Shot Prompting) 🚀

</div>

این یکی از تکنیک‌های خیلی قدرتمنده! به جای اینکه فقط دستور بدید، **چند تا مثال از کاری که می‌خواید انجام بشه رو به مدل نشون می‌دید.** مدل از روی مثال‌های شما الگو رو یاد می‌گیره و کار رو برای ورودی جدیدتون انجام می‌ده. به این روش میگن **Few-Shot Prompting** (یعنی یادگیری با چند مثال).

**مثال: تشخیص حس متن (Sentiment Analysis)**

```markdown
حس متن‌های زیر رو مشخص کن (مثبت، منفی، خنثی).

متن: من عاشق این رستورانم! غذاش عالیه!
حس: مثبت

متن: متاسفانه کیفیت خدمات خیلی پایین بود.
حس: منفی

متن: این کتاب درباره تاریخ ایران است.
حس: خنثی

حالا حس این متن رو بگو:
متن: فیلم خوبی بود، ارزش دیدن داره.
حس: ؟
```

**پاسخ احتمالی:**
`مثبت`

**مثال دیگه: تبدیل لحن**

```markdown
لحن جمله زیر رو از رسمی به خودمونی تغییر بده.

جمله رسمی: احتراما به استحضار می‌رساند جلسه فردا لغو گردیده است.
جمله خودمونی: بچه‌ها، جلسه فردا کنسله!

حالا این جمله رو خودمونی کن:
جمله رسمی: لطفاً در اسرع وقت نسبت به تکمیل فرم اقدام فرمایید.
جمله خودمونی: ؟
```

**پاسخ احتمالی:**
`لطفاً هر چی زودتر فرم رو پر کنید.`

**کی به درد می‌خوره؟**
*   وقتی می‌خواید مدل یه **الگوی خاص** رو یاد بگیره (مثل طبقه‌بندی، تبدیل فرمت، تشخیص حس).
*   وقتی توضیح دادن دقیق کاری که می‌خواید سخته، اما **نشون دادنش با مثال راحته**.
*   وقتی می‌خواید خروجی **دقیقاً شبیه مثال‌های شما** باشه.

---

<br>

<div align="center">

## ۶. ازش بخواه قدم به قدم فکر کنه و بعد جواب بده 🧩

</div>

گاهی اوقات، مخصوصاً برای مسائل پیچیده‌تر (مثل مسائل ریاضی یا استدلالی)، اگه از مدل بخواید **قبل از دادن جواب نهایی، مراحل فکر کردنش رو هم بنویسه**، نتیجه بهتری می‌گیرید. انگار دارید بهش می‌گید "بلند بلند فکر کن!". به این تکنیک گاهی **Chain-of-Thought (زنجیره فکر)** هم می‌گن.

**مثال: حل مسئله ریاضی**

```markdown
لطفاً مسئله زیر رو مرحله به مرحله حل کن و در نهایت جواب آخر رو بنویس:

سوال: قیمت یک دفتر ۱۲ هزار تومان است و قیمت یک خودکار ۸ هزار تومان. اگر ۳ دفتر و ۲ خودکار بخریم، کل هزینه چقدر می‌شود؟

مراحل حل:
۱. محاسبه قیمت ۳ دفتر: ۳ * ۱۲۰۰۰ = ۳۶۰۰۰ تومان
۲. محاسبه قیمت ۲ خودکار: ۲ * ۸۰۰۰ = ۱۶۰۰۰ تومان
۳. محاسبه هزینه کل: ۳۶۰۰۰ + ۱۶۰۰۰ = ۵۲۰۰۰ تومان

جواب نهایی: ۵۲۰۰۰ تومان
```
*(توجه: در پرامپت واقعی، شما فقط سوال رو می‌دید و از مدل می‌خواید مراحل و جواب رو بنویسه. اینجا فقط برای نمایش کامل آوردم)*

**چرا این روش خوبه؟**
*   به مدل **فرصت می‌ده** تا مسئله رو تجزیه کنه و احتمال اشتباهش کمتر می‌شه.
*   اگه جواب نهایی اشتباه بود، می‌تونید **مراحل رو ببینید** و بفهمید کجای کار ایراد داشته.
*   برای مسائلی که نیاز به **استدلال چند مرحله‌ای** دارن، خیلی کمک‌کننده‌ست.

---

<br>

<div align="center">

## ۷. بار اول نشد؟ دوباره و دوباره امتحان کن! (تکرار و بهبود) 🔄

</div>

خیلی مهمه که بدونید: **نوشتن پرامپت یه مهارته و مثل هر مهارت دیگه‌ای با تمرین بهتر می‌شه!** خیلی کم پیش میاد که با همون اولین پرامپتی که می‌نویسید، دقیقاً به بهترین جواب ممکن برسید.

پس **اصلاً ناامید نشید!** فرایند کار معمولاً اینطوریه:

1.  **یه پرامپت اولیه بنویسید** و نتیجه رو ببینید.
2.  **جواب مدل رو تحلیل کنید:** آیا دقیقاً همونیه که می‌خواستید؟ کجاش خوبه؟ کجاش ایراد داره؟ آیا چیزی رو اشتباه فهمیده؟
3.  **پرامپت‌تون رو اصلاح کنید:** شاید باید واضح‌تر بگید چی می‌خواید، شاید باید مثال اضافه کنید، شاید باید لحن رو مشخص کنید، یا از یکی از تکنیک‌هایی که گفتیم استفاده کنید.
4.  **دوباره امتحان کنید** و این چرخه رو اونقدر تکرار کنید تا به نتیجه دلخواه‌تون برسید.

**پرامپت‌نویسی یه جورایی مثل آشپزیه؛ باید هی مواد اولیه (دستورات) رو کم و زیاد کنید و تست کنید تا به اون طعم عالی برسید!** 😉

---

<br>

<div align="center">

### جمع‌بندی: جعبه ابزار پرامپت‌نویسی حرفه‌ای ✨

</div>

پس دیدیم که با چند تا تکنیک ساده اما کاربردی می‌تونیم کنترل خیلی بیشتری روی جواب‌های LLM داشته باشیم:

*   **جدا کردن دستور و داده:** با جداکننده‌ها (` ``` `، `###` و...).
*   **درخواست فرمت خاص خروجی:** مثل JSON، لیست، جدول.
*   **تعیین لحن و سبک:** رسمی، دوستانه، طنز، یا حتی یه شخصیت خاص.
*   **گذاشتن شرط برای مدل:** اول چک کن، بعد جواب بده.
*   **یاد دادن با مثال (Few-Shot):** الگو رو نشون بده تا یاد بگیره.
*   **درخواست فکر کردن مرحله به مرحله (Chain-of-Thought):** برای مسائل پیچیده‌تر.
*   **تکرار و بهبود مداوم:** کلید اصلی برای رسیدن به بهترین نتیجه.

با استفاده از این تکنیک‌ها، می‌تونید از یه کاربر معمولی LLM به یه **کاربر حرفه‌ای** تبدیل بشید و جواب‌های خیلی دقیق‌تر، مفیدتر و خلاقانه‌تری از این مدل‌ها بگیرید!

<br>


---

<br>

<div align="center">

# پارامترهای مهم در کار با LLMها ⚙️

</div>

**نکته‌ی مهم:** اگه فقط با چت‌بات‌های معمولی مثل ChatGPT یا Gemini کار می‌کنی، احتمالاً نیازی به دستکاری این پارامترها نداری یا اصلاً بهشون دسترسی نداری. ولی دونستن‌شون کمک می‌کنه بفهمی پشت صحنه چه خبره. 😉
**اما:** اگه برنامه‌نویسی می‌کنی و داری از **API** مدل‌ها استفاده می‌کنی، یا می‌خوای خروجی‌های خیلی خاص و کنترل‌شده بگیری (مثلاً برای تولید محتوای خلاقانه، کدنویسی دقیق، تحلیل متن، یا ساختن ربات‌های خاص)، این پارامترها مثل **دکمه‌های تنظیم جادویی** برات عمل می‌کنن! باهاشون می‌تونی رفتار مدل رو دقیقاً اونجوری که می‌خوای شکل بدی.

---

<br>

<div align="center">

## مقدار Temperature (دمای خلاقیت / دقت) 🌡️

</div>

#### **چی هست؟**
مثل یه **ولوم خلاقیت** برای مدل می‌مونه. تعیین می‌کنه مدل چقدر در انتخاب کلمه‌ی بعدی "ریسک" کنه. یعنی چقدر جواب‌هاش قابل پیش‌بینی یا خلاقانه و غیرمنتظره باشه.

#### **عدد کم (مثلاً `0.1` یا `0.2`)**:
*   **رفتار مدل:** مدل **محافظه‌کار** و **دقیق** می‌شه. جواب‌های **معمول، قابل پیش‌بینی** و خیلی نزدیک به محتمل‌ترین گزینه‌ها رو می‌ده. انگار داره از روی یه متن خیلی خشک و مشخص می‌خونه.
*   **کِی به درد می‌خوره؟ (مثال واقعی):**
    *   **توضیح کد (Code Explanation):** می‌خوای یه کد پایتون رو خط به خط توضیح بده. نیاز به دقت ۱۰۰٪ داری، نه تفسیر خلاقانه. `temperature=0.1` عالیه.
    *   **استخراج اطلاعات (Data Extraction):** می‌خوای شماره تلفن، ایمیل یا تاریخ‌ها رو از یه متن طولانی بکشی بیرون. دمای پایین جلوی "توهم زدن" (Hallucination) و ساختن اطلاعات الکی رو می‌گیره.
    *   **پاسخ به سوالات با جواب مشخص (Fact-based Q&A):** جواب سوال "پایتخت فرانسه کجاست؟" باید همیشه "پاریس" باشه، نه یه شعر در مورد پاریس!

#### **عدد زیاد (مثلاً `0.8` یا `1.0`)**:
*   **رفتار مدل:** مدل **جسور و خلاق** می‌شه! جواب‌های **غیرمنتظره، متنوع، جدید** و گاهی حتی بامزه می‌ده. انگار یه نویسنده یا ایده‌پرداز داره برات می‌نویسه.
*   **کِی به درد می‌خوره؟ (مثال واقعی):**
    *   **ایده‌پردازی (Brainstorming):** دنبال ایده‌های جدید برای داستان، کمپین تبلیغاتی، یا اسم برای یه محصولی؟ `temperature=0.9` مدل رو هل می‌ده که خارج از چارچوب فکر کنه.
    *   **نوشتن متن خلاقانه (Creative Writing):** برای نوشتن شعر، داستان کوتاه، یا دیالوگ‌های جذاب، دمای بالا کمک می‌کنه متن زنده و غیرتکراری بشه.
    *   **تولید شعار تبلیغاتی (Slogan Generation):** نیاز به شعارهای گیرا و متفاوت داری؟ دما رو ببر بالا!

**هشدار:** اگه دما رو **خیلی** بالا ببری (نزدیک به `1` یا بیشتر، اگه API اجازه بده)، ممکنه مدل پرت‌وپلا بگه و جواب‌هاش بی‌ربط و عجیب غریب بشن. حواست باشه!

---

<br>

<div align="center">

## مقدار Top-p (نمونه‌برداری هسته‌ای / Nucleus Sampling) 🎲

</div>

#### **چی هست؟**
اینم یه راه دیگه برای کنترل خلاقیت، ولی یه کم هوشمندتر از Temperature. به مدل می‌گه: "به جای اینکه بین *همه‌ی* کلمات ممکن بعدی انتخاب کنی، فقط اون کلماتی رو در نظر بگیر که **مجموع احتمالشون** به عدد `p` برسه". انگار یه **دایره‌ی لغات مجاز پویا** برای هر قدم تعریف می‌کنه.

#### **عدد کم (مثلاً `0.1` یا `0.2`)**:
*   **رفتار مدل:** دایره‌ی انتخاب کلمات خیلی **کوچیک و محدود** می‌شه. مدل فقط می‌تونه از بین یکی دو تا کلمه‌ی خیلی خیلی محتمل انتخاب کنه. جواب‌ها **یکنواخت و قابل پیش‌بینی** می‌شن.
*   **کِی به درد می‌خوره؟ (مثال واقعی):**
    *   **ساخت ربات پاسخگویی به سوالات متداول (FAQ Bot):** می‌خوای جواب‌ها کوتاه، استاندارد و همیشه شبیه هم باشن؟ `top_p=0.1` کمک می‌کنه مدل زیادی خلاق نشه و جواب‌های یکدست بده.
    *   **تکمیل جملات مشخص (Sentence Completion in Forms):** اگه داری فرمی رو پر می‌کنی و می‌خوای مدل فقط محتمل‌ترین کلمه‌ی بعدی رو پیشنهاد بده، Top-p پایین خوبه.

#### **عدد زیاد (مثلاً `0.9` یا `0.95`)**:
*   **رفتار مدل:** دایره‌ی انتخاب **گسترده‌تر** می‌شه و کلمات بیشتری (حتی اونایی که یه کم کمتر محتملن ولی مناسبن) شانس انتخاب شدن پیدا می‌کنن. متن **متنوع‌تر و جذاب‌تر** می‌شه.
*   **کِی به درد می‌خوره؟ (مثال واقعی):**
    *   **نوشتن پست وبلاگ یا مقاله:** می‌خوای توصیفات زنده و واژگان غنی باشن؟ `top_p=0.9` به مدل اجازه می‌ده از صفت‌ها و فعل‌های متنوع‌تری استفاده کنه و متن خسته‌کننده نشه.
    *   **تولید محتوای شبکه‌های اجتماعی:** می‌خوای کپشن‌ها جذاب و غیرتکراری باشن؟ Top-p بالا کمک می‌کنه لحن طبیعی‌تر و پویاتر باشه.

**نکته:** معمولاً یا از `Temperature` استفاده می‌کنن یا از `Top-p`. استفاده همزمان از هر دو هم ممکنه، ولی باید با دقت تنظیم بشه چون می‌تونن اثر هم رو پیچیده کنن. خیلیا `Top-p` رو ترجیح می‌دن چون به نظر می‌رسه کنترل بهتری روی جلوگیری از کلمات بی‌ربط می‌ده، حتی وقتی خلاقیت بالاست.

---

<br>

<div align="center">

## مقدار Frequency Penalty (جریمه تکرار کلمه) 🔄

</div>

#### **چی هست؟**
این پارامتر مدل رو **جریمه می‌کنه** اگه بخواد یه **کلمه خاص** رو **زیاد تکرار** کنه. هرچی عددش بالاتر باشه (معمولاً بین 0 تا 2)، مدل بیشتر سعی می‌کنه از اون کلمه دوری کنه و دنبال جایگزین بگرده.

#### **عدد کم (مثلاً `0` یا `0.2`)**:
*   **رفتار مدل:** مدل هیچ جریمه‌ای نمی‌شه و راحت کلمات رو تکرار می‌کنه.
*   **کِی به درد می‌خوره؟ (مثال واقعی):**
    *   **نوشتن مستندات فنی (Technical Documentation):** لازمه اسم یه تابع خاص، مثلاً `getUserProfile()`، بارها تکرار بشه تا متن دقیق باشه. `frequency_penalty=0` اینجا عالیه.
    *   **متن‌های کوتاه:** اگه داری فقط یه جمله یا پاراگراف کوتاه می‌نویسی، تکرار کلمه شاید اصلاً مهم نباشه.

#### **عدد زیاد (مثلاً `1.0` یا `1.5`)**:
*   **رفتار مدل:** مدل **مجبور می‌شه** خلاقیت به خرج بده و از تکرار بیش از حد کلمات کلیدی پرهیز کنه.
*   **کِی به درد می‌خوره؟ (مثال واقعی):**
    *   **نوشتن نقد فیلم یا کتاب طولانی:** اگه مدل هی بگه "فیلم خیلی خوب بود"، متن ضعیف می‌شه. با `frequency_penalty=1.2`، مدل مجبوره بگه "جذاب بود"، "تاثیرگذار بود"، "خوش‌ساخت بود" و ... .
    *   **تولید مقاله‌های طولانی:** برای اینکه متن روان و خواندنی باشه و خواننده خسته نشه، این پارامتر کمک می‌کنه تنوع لغات حفظ بشه.

---

<br>

<div align="center">

## مقدار Presence Penalty (جریمه تکرار موضوع/توکن) 🚫

</div>

#### **چی هست؟**
این یکی شبیه قبلیه، ولی یه کم سخت‌گیرتر! به جای اینکه *تعداد دفعات* تکرار یه کلمه رو جریمه کنه، به محض اینکه یه کلمه (یا دقیق‌تر بگیم، یه توکن) **حداقل یک بار** در متن ظاهر شد، احتمال استفاده‌ی دوباره ازش رو کم می‌کنه (جریمه‌ش برای بار دوم، سوم، ... معمولاً یکسانه). هدف اصلیش اینه که مدل رو تشویق کنه **موضوعات و کلمات جدید** رو به بحث اضافه کنه. مقدارش معمولاً بین 0 تا 2 هست.

#### **عدد کم (`0` یا `0.2`)**:
*   **رفتار مدل:** مدل آزاده که روی مفاهیم و کلماتی که قبلاً معرفی کرده، دوباره تاکید کنه.
*   **کِی به درد می‌خوره؟ (مثال واقعی):**
    *   **نوشتن متن آموزشی:** داری "زنجیره بلوکی (Blockchain)" رو توضیح می‌دی؟ لازمه مفاهیم کلیدی مثل "بلاک"، "هش"، "دفتر کل توزیع‌شده" چند بار تکرار بشن تا جا بیفتن. `presence_penalty=0` به مدل این اجازه رو می‌ده.
    *   **تمرکز روی یک موضوع خاص:** اگه می‌خوای مدل فقط و فقط در مورد یه موضوع خاص حرف بزنه و از شاخه‌ای به شاخه‌ی دیگه نپره، این پارامتر رو پایین نگه دار.

#### **عدد زیاد (`1.0` یا `1.5`)**:
*   **رفتار مدل:** مدل به شدت تشویق می‌شه که **حرف‌های جدید** بزنه و از پرداختن مکرر به یه موضوع یا استفاده مکرر از کلماتی که قبلاً گفته، خودداری کنه.
*   **کِی به درد می‌خوره؟ (مثال واقعی):**
    *   **تولید لیست ایده‌های متنوع:** می‌خوای لیستی از ایده‌های کاملاً متفاوت برای سفر، آشپزی، تکنولوژی و ... تولید کنی؟ `presence_penalty=1.0` مدل رو مجبور می‌کنه بعد از گفتن "سفر به تایلند"، سراغ موضوعات دیگه بره و هی نگه "جاهای دیدنی تایلند"، "غذای تایلندی" و ... .
    *   **جلسات طوفان فکری (Brainstorming) گسترده:** وقتی می‌خوای حداکثر ایده‌های جدید و متنوع رو استخراج کنی، این پارامتر کمک می‌کنه مدل در یک مسیر گیر نکنه.

---

<br>

<div align="center">

## مقدار Top-k (گزینش از k تای برتر) 📝

</div>

#### **چی هست؟**
این پارامتر خیلی سرراسته. به مدل می‌گه در هر مرحله، فقط از بین **k** تا از محتمل‌ترین کلمات بعدی، یکی رو انتخاب کن. بقیه‌ی کلمات، حتی اگه احتمالشون خیلی هم کم نباشه، کلاً از دایره‌ی انتخاب حذف می‌شن.

#### **عدد کم (مثلاً `1` یا `3`)**:
*   **رفتار مدل:** انتخاب‌ها **بسیار محدود** و خروجی **خیلی قابل پیش‌بینی** می‌شه. اگه `k=1` باشه، مدل همیشه فقط و فقط محتمل‌ترین کلمه رو انتخاب می‌کنه (بهش می‌گن حالت Greedy یا حریصانه).
*   **کِی به درد می‌خوره؟ (مثال واقعی):**
    *   **تکمیل خودکار دستورات (Autocomplete):** داری یه ابزار برای تکمیل دستورات لینوکس می‌سازی؟ می‌خوای فقط ۲-۳ تا از محتمل‌ترین دستورات بعدی رو پیشنهاد بده، نه یه لیست طولانی. `top_k=3` مناسبه.
    *   **کاربردهای خیلی دقیق و بدون خطا:** مواقعی که فقط یک جواب درست وجود داره و نمی‌خوای هیچ ریسکی بکنی.

#### **عدد زیاد (مثلاً `40` یا `50`)**:
*   **رفتار مدل:** مدل گزینه‌های بیشتری برای انتخاب داره، که می‌تونه منجر به **تنوع بیشتر** بشه. ولی همچنان انتخاب‌ها رو به `k` تای برتر محدود می‌کنه و جلوی انتخاب کلمات خیلی خیلی نامحتمل رو می‌گیره.
*   **کِی به درد می‌خوره؟ (مثال واقعی):**
    *   **نوشتن دیالوگ برای شخصیت‌های بازی:** می‌خوای شخصیت یه کم غیرقابل‌پیش‌بینی باشه، ولی پرت و پلا نگه؟ `top_k=50` به مدل یه فضای خوبی برای انتخاب می‌ده بدون اینکه خیلی عجیب غریب بشه. (متفاوت از Top-p که بر اساس احتمال تجمعی کار می‌کنه).

#### **مقایسه با Top-p:**
مقدار `Top-k` تعداد *ثابتی* از کلمات رو در نظر می‌گیره (مثلاً ۵۰ تا). `Top-p` تعداد *متغیری* از کلمات رو بر اساس *مجموع احتمال* انتخاب می‌کنه (مثلاً هر تعداد کلمه‌ای که لازم باشه تا جمع احتمالشون ۹۰٪ بشه). برای همین `Top-p` معمولاً انعطاف‌پذیرتر و محبوب‌تره، ولی `Top-k` هم ساده‌تره و برای بعضی کارها خوب جواب می‌ده.

---

<br>

<div align="center">

## 🤔 خلاصه تفاوت پارامترها به زبان ساده

</div>

*   مقدار **Temperature:** مثل **ولوم خلاقیت/ریسک‌پذیری**. کم یعنی قابل پیش‌بینی، زیاد یعنی خلاق و غیرمنتظره.
*   مقدار **Top-p:** مثل **اندازه دایره لغات مجاز** در هر لحظه (بر اساس جمع احتمال). کم یعنی فقط کلمات خیلی محتمل، زیاد یعنی کلمات متنوع‌تر.
*   مقدار **Frequency Penalty:** **جریمه تکرار *زیادِ همون کلمه***. زیاد یعنی مدل کمتر کلمات رو تکرار می‌کنه.
*   مقدار **Presence Penalty:** **جریمه تکرار *حتی یک‌باره‌ی همون ایده یا کلمه***. زیاد یعنی مدل بیشتر سراغ ایده‌ها و کلمات جدید می‌ره.
*   مقدار **Top-k:** **محدود کردن تعداد کلمات انتخابی** به *k* تای اول. کم یعنی انتخاب‌های خیلی محدود، زیاد یعنی انتخاب‌های بیشتر (ولی سقف داره).

---


<br>

<div align="center">

## یه پیشنهاد کاربردی در آخر

</div>

اگه مطمئن نیستی دقیقاً چه ترکیبی از این پارامترها برای کار *تو* بهتره، می‌تونی **از خود مدل کمک بگیری!** (البته این سوال رو توی چت با مدل می‌پرسی، نه توی تنظیمات API). مثلاً بپرس:

```
سلام، من دارم از API شما استفاده می‌کنم تا بتونم خلاصه‌های خیلی کوتاه و دقیق از مقالات علمی طولانی تهیه کنم. هدف اصلیم اینه که خلاصه کاملاً به متن اصلی وفادار باشه، اطلاعات کلیدی رو منتقل کنه و هیچ تفسیر یا خلاقیت اضافه‌ای نداشته باشه.
برای این کار، به نظرت بهترین مقادیر پیشنهادی برای پارامترهای temperature، top_p، frequency_penalty و presence_penalty چی هستن؟ لطفاً راهنماییم کن.
```

مدل احتمالاً یه همچین جوابی بهت می‌ده:

> **پاسخ نمونه:**
> "سلام! برای تولید خلاصه‌های دقیق و مبتنی بر واقعیت از مقالات علمی، پیشنهاد می‌کنم تنظیمات زیر رو امتحان کنی:
> *   مقدار `temperature`: مقدار خیلی پایینی مثل `0.1` تا `0.3` رو امتحان کن. این کمک می‌کنه مدل به محتمل‌ترین و دقیق‌ترین کلمات پایبند بمونه و از خودش چیزی اضافه نکنه.
> *   مقدار `top_p`: چون temperature رو خیلی پایین آوردی، احتمالاً نیازی به تنظیم top_p نیست (می‌تونی روی `1.0` بذاریش). تنظیم همزمان هر دو روی مقادیر پایین ممکنه خروجی رو زیادی محدود و خشک کنه.
> *   مقدار `frequency_penalty`: می‌تونه یه مقدار کم مثبت باشه، مثلاً `0.2` تا `0.5`. این باعث می‌شه کلمات تخصصی بیش از حد تکرار نشن، ولی نه اونقدر که به متن آسیب بزنه.
> *   مقدار `presence_penalty`: بهتره نزدیک به `0` باشه (مثلاً `0` یا `0.1`). چون در خلاصه، ممکنه لازم باشه مفاهیم و اصطلاحات کلیدی مقاله چند بار تکرار بشن تا منظور دقیق منتقل بشه.
>
> یادت باشه این‌ها نقطه شروع هستن. بهترین کار اینه که با چند تا مقاله نمونه، این مقادیر رو کمی تغییر بدی و ببینی کدوم ترکیب بهترین نتیجه رو برای نیاز خاص تو می‌ده."

به همین سادگی! می‌تونی از خود مدل به عنوان یه مشاور اولیه برای تنظیم پارامترها استفاده کنی.

<br>

---
<br>

<div align="center">

# System Prompt 🤖

</div>

<div align="center">

## تعریف System Prompt

</div>

سیستم پرامپت همون پرامپتیه که **اول کار** به مدل داده می‌شه تا **چارچوب رفتاری** و **نوع پاسخ‌ها** رو مشخص کنه. مثلاً می‌تونی به مدل بگی **مودب باشه** یا **همیشه خروجی رو به فرمت JSON بده**. این تنظیمات یک‌بار انجام می‌شن و تا آخر مکالمه ثابت می‌مونن.

---

<div align="center">

## چطور کار می‌کنه؟ ⚙️

</div>

وقتی System Prompt رو **تنظیم می‌کنی**، مدل از اون به بعد **طبق همون راهنما** جواب می‌ده. دیگه لازم نیست **هردفعه** تکرارش کنی. فقط کافیه **یه بار** بگی که مدل چه سبک و رویکردی داشته باشه.

---

<div align="center">

### مثال کاربردی 📚

</div>

فرض کن می‌خوای مدل مثل یه مربی ورزشی جواب بده:

**سیستم پرامپت:**

```
تو یه مربی ورزشی هستی که همیشه با انرژی و انگیزه صحبت می‌کنه.
کاربران رو تشویق می‌کنی تا به اهداف ورزشی برسن.
توصیه‌ها و برنامه‌های تمرینی رو ساده و قابل فهم توضیح بده.
```

**پرامپت:**

```
برای مسابقه دویدن ۱۰ کیلومتری چطور آماده بشم؟
```

**جواب (نمونه):**

```
سلام! برای مسابقه ۱۰ کیلومتری، سه بار در هفته به صورت منظم تمرین کن. 
هر هفته کمی مسافت رو بیشتر کن تا بدن‌ت عادت کنه.
فراموش نکن تغذیه مناسب و استراحت کافی داشته باشی.
...
```

---

<div align="center">

## چرا System Prompt مهمه؟ 🤔

</div>

- **یک‌بار تنظیم می‌شه:** دیگه نیازی به تکرار مداوم دستورها نداری.  
- **مشخص کردن رفتار کلی مدل:** مثلاً لحن مودبانه یا خروجی ساختاریافته.  
- **سادگی و کارآمدی:** مکالمه رو روان‌تر می‌کنه.  
- **یکپارچگی خروجی‌ها:** جواب‌ها همیشه **منسجم** و در **یک سبک ثابت** ارائه می‌شن.  
- **کنترل بیشتر:** می‌تونی **دقیقاً** تعیین کنی که مدل چطور جواب بده.  

<br>

---

<br>

<div align="center">

# تکنیک‌های پرامپت‌نویسی 📜

</div>

اگه می‌خوای از یه **مدل زبانی (LLM)** خروجی دقیق و مفید بگیری، باید **پرامپت** خودت رو با دقت طراحی کنی. پرامپت خوب مثل یه نقشه راه دقیق برای مدله. توی این بخش، چند **تکنیک مهم** رو معرفی می‌کنیم که با کمکشون می‌تونی **کارآمدترین** پرامپت‌ها رو بسازی و بهترین جواب‌ها رو از مدل بگیری.

---

<br>

<div align="center">

## ۱. نقش‌دهی (Role Prompting) 🎭

</div>

اینجا به مدل می‌گیم که **نقش یه شخصیت یا متخصص خاص** رو بازی کنه. انگار داری به یه بازیگر می‌گی چه نقشی رو اجرا کنه.

**چرا مفیده؟**
- مدل می‌فهمه باید با چه **لحن، سبک و سطح دانشی** جواب بده.
- جواب‌هاش **هدفمندتر و مرتبط‌تر** با نیاز شما می‌شه.

**مثال:**
```
# سیستم پرامپت (دستور اولیه به مدل)
تو یه آشپز حرفه‌ای ایتالیایی هستی. با هیجان و اشتیاق در مورد غذاها صحبت کن و از اصطلاحات ایتالیایی ساده هم استفاده کن.

# پرامپت کاربر
چطور یه پاستا کاربونارای اصیل درست کنم؟

# جواب مدل (نمونه)
"به‌به! کاربونارا! غذای روح ایتالیاست! برای یه کاربونارای عالی (perfetto!)، اول پاستا رو بجوشون. بعد تخم‌مرغ، پنیر پکورینو و فلفل سیاه رو مخلوط کن. گوشت گوانچاله (یا بیکن) رو سرخ کن و روغن اضافه رو بگیر. پاستا رو با مخلوط تخم‌مرغ قاطی کن و در آخر گوشت سرخ‌شده رو بریز روش. نوش جان (Buon appetito)! "
```

**نکته تکمیلی:**
- می‌تونی نقش‌های ترکیبی هم بدی (مثلاً "یه برنامه‌نویس پایتون که مثل معلم مدرسه توضیح می‌ده")، ولی حواست باشه نقش‌ها واضح باشن تا مدل گیج نشه.

---

<br>

<div align="center">

## ۲. ارائه چند مثال (Few-Shot Prompting) 📚
</div>

توی این روش، قبل از اینکه سوال اصلی رو بپرسی، **چند تا مثال از کاری که می‌خوای** به مدل نشون می‌دی. مثل این می‌مونه که به یه دانش‌آموز چند نمونه سوال حل‌شده بدی تا روش کار دستش بیاد.

**چرا مفیده؟**
- مدل **الگوی جواب دادن** رو یاد می‌گیره (فرمت، سبک، نوع اطلاعات).
- برای کارهایی که نیاز به **قالب‌بندی خاص** دارن (مثل تبدیل متن به جدول) یا کارهایی که مدل اولش خوب نمی‌فهمه، عالیه.

**مثال (استخراج اطلاعات کلیدی از متن):**
```
# مثال ۱
متن: سیب قرمز و شیرین است.
رنگ: قرمز
مزه: شیرین

# مثال ۲
متن: لیمو ترش و زرد است.
رنگ: زرد
مزه: ترش

# حالا سوال اصلی
متن: پرتقال نارنجی و کمی ترش است.
رنگ: ؟
مزه: ؟

# جواب مدل:
رنگ: نارنجی
مزه: کمی ترش
```

**نکته تکمیلی:**
- هرچی مثال‌ها به کار اصلی شما شبیه‌تر باشن، نتیجه بهتر می‌شه. برای کارهای پیچیده‌تر مثل طبقه‌بندی متن یا خلاصه‌نویسی با سبک خاص، خیلی کاربردیه.

---

<br>

<div align="center">

## ۳. زنجیره تفکر (Chain of Thought Prompting - CoT) 🧠
</div>

اینجا از مدل می‌خوایم که **فقط جواب نهایی رو نگه**، بلکه **مراحل فکر کردن و رسیدن به جواب** رو هم بنویسه. انگار داری بهش می‌گی "روند حل مسئله رو هم نشونم بده".

**چرا مفیده؟**
- برای **مسائل پیچیده** (مثل ریاضی، منطق یا برنامه‌ریزی) که نیاز به استدلال چند مرحله‌ای دارن، عالیه.
- باعث می‌شه مدل **کمتر اشتباه کنه** چون مجبوره قدم‌به‌قدم فکر کنه.
- اگه مدل اشتباه کرد، می‌فهمی **کجای مسیر فکریش** مشکل داشته.

**مثال (مسئله ریاضی):**
```
# پرامپت کاربر
سوال: علی ۳ تا سیب داشت. ۲ تا دیگه خرید. بعد نصف سیب‌هاش رو به دوستش داد. الان چند تا سیب داره؟ لطفاً مراحل محاسبه رو بنویس.

# جواب مدل (نمونه)
۱. علی اول ۳ تا سیب داشت.
۲. بعد ۲ تا دیگه خرید، پس تعداد سیب‌هاش شد: ۳ + ۲ = ۵ تا.
۳. نصف سیب‌هاش رو به دوستش داد، یعنی: ۵ / ۲ = ۲.۵ تا.
۴. پس الان علی ۲.۵ سیب داره.
جواب نهایی: ۲.۵
```

**نکته تکمیلی:**
- می‌تونی حتی بخوای اول فقط مراحل رو بگه و بعد جواب نهایی رو در خط جدا بنویسه. اینطوری بررسی کردنش راحت‌تره.

---

<br>

<div align="center">

## ۴. درخت تفکر (Tree of Thoughts - ToT) 🌳
</div>

این تکنیک یه جورایی نسخه **پیشرفته‌تر زنجیره تفکره**. به جای اینکه فقط یه مسیر فکری رو دنبال کنه، مدل تشویق می‌شه که **چندین مسیر مختلف فکری** رو همزمان بررسی کنه، هر کدوم رو ارزیابی کنه و در نهایت **بهترین مسیر** رو برای رسیدن به جواب انتخاب کنه. مثل یه درخت که چندین شاخه داره و هر شاخه یه راه حل ممکنه.

**چرا مفیده؟**
- برای مسائلی که **راه‌حل‌های ممکن زیادی** دارن یا نیاز به **برنامه‌ریزی و خلاقیت** بیشتری دارن (مثل نوشتن داستان با پایان‌های مختلف، حل معماهای پیچیده، یا پیدا کردن بهترین استراتژی).
- به مدل کمک می‌کنه **گزینه‌های بیشتری** رو در نظر بگیره و جواب **جامع‌تر و بهتری** بده.

**مثال (برنامه‌ریزی ساده):**
```
# پرامپت کاربر
"من می‌خوام برای آخر هفته یه سفر کوتاه برم. سه تا گزینه دارم: برم جنگل، برم کنار دریا، یا بمونم تو شهر و برم موزه. لطفاً مزایا و معایب هر کدوم رو بررسی کن و بگو کدوم بهترین گزینه است، با در نظر گرفتن اینکه هوا ممکنه بارونی باشه و من دنبال آرامش هستم."

# جواب مدل (نمونه با رویکرد ToT)
"باشه، بیا بررسی کنیم:

*   **شاخه ۱: رفتن به جنگل**
    *   مزایا: آرامش، طبیعت زیبا، هوای تازه.
    *   معایب: اگه بارون بیاد، گلی می‌شه و شاید نشه زیاد راه رفت. امکانات کمتره.
    *   ارزیابی: آرامش داره ولی ریسک بارون زیاده.

*   **شاخه ۲: رفتن کنار دریا**
    *   مزایا: صدای موج آرامش‌بخشه، منظره باز.
    *   معایب: بارون بیاد زیاد جالب نیست. ممکنه شلوغ باشه.
    *   ارزیابی: آرامش داره ولی بارون و شلوغی مشکل‌سازه.

*   **شاخه ۳: موندن در شهر و رفتن به موزه**
    *   مزایا: تحت تاثیر بارون نیست. فعالیت فرهنگی و آرومه.
    *   معایب: هیجان طبیعت رو نداره. ممکنه هزینه بیشتری داشته باشه.
    *   ارزیابی: آرامش داره و از بارون در امانه، ولی حس سفر نداره.

*   **نتیجه‌گیری:** با توجه به احتمال بارون و نیاز به آرامش، به نظر می‌رسه **موندن در شهر و رفتن به موزه** گزینه کم‌ریسک‌تر و مطمئن‌تری برای آرامش باشه. اگه ریسک بارون رو قبول کنی، جنگل هم خوبه."
```

**نکته تکمیلی:**
- پیاده‌سازی کامل ToT معمولاً نیاز به کدنویسی داره تا بشه واقعاً چند مسیر رو مدیریت و ارزیابی کرد، ولی با پرامپت‌نویسی هوشمند می‌شه مدل رو تشویق کرد تا شبیه به این روش فکر کنه.

---

<br>

<div align="center">

## ۵. استدلال و عمل (ReAct - Reasoning and Acting) ⚙️
</div>

این تکنیک به مدل اجازه می‌ده که **فقط فکر نکنه، بلکه عمل هم بکنه!** یعنی مدل می‌تونه بین **مراحل استدلال (فکر کردن)** و **انجام یک عمل (مثل جستجو در وب، استفاده از ماشین حساب، یا فراخوانی یه ابزار دیگه)** جابجا بشه تا اطلاعات لازم رو به دست بیاره و بعد به جواب نهایی برسه.

**چرا مفیده؟**
- مدل می‌تونه به **اطلاعات به‌روز** دسترسی پیدا کنه (مثلاً قیمت لحظه‌ای دلار یا وضعیت آب‌وهوا).
- می‌تونه **محاسبات پیچیده** رو به ابزار دیگه‌ای بسپاره و از اشتباهات ریاضی جلوگیری کنه.
- مدل رو قادر می‌کنه با **دنیای بیرون** (از طریق ابزارها و APIها) تعامل داشته باشه.

**مثال (پاسخ به سوالی که نیاز به اطلاعات بیرونی داره):**
```
# پرامپت کاربر
"پایتخت فرانسه کجاست و الان اونجا ساعت چنده؟"

# روند فکری و عملی مدل (با رویکرد ReAct - به صورت فرضی)
*   **فکر (Reasoning):** سوال دو بخش داره: پایتخت فرانسه و ساعت فعلی اونجا. بخش اول اطلاعات ثابته، ولی بخش دوم نیاز به اطلاعات به‌روز داره.
*   **عمل (Action):** جستجوی وب برای "پایتخت فرانسه".
*   **مشاهده (Observation):** نتیجه جستجو: پاریس.
*   **فکر (Reasoning):** خب، پایتخت پاریسه. حالا باید ساعت پاریس رو پیدا کنم.
*   **عمل (Action):** جستجوی وب برای "ساعت فعلی در پاریس".
*   **مشاهده (Observation):** نتیجه جستجو: ساعت فعلی در پاریس [ساعت فعلی] است.
*   **فکر (Reasoning):** حالا هر دو بخش جواب رو دارم. می‌تونم جواب نهایی رو بدم.

# جواب نهایی مدل:
"پایتخت فرانسه پاریس است. ساعت فعلی در پاریس [ساعت فعلی] می‌باشد."
```

**نکته تکمیلی:**
- ReAct معمولاً در سیستم‌هایی پیاده‌سازی می‌شه که مدل به ابزارهای خارجی (مثل موتور جستجو، ماشین حساب، APIهای مختلف) دسترسی داره.

---

<br>

<div align="center">

## ۶. خود-سازگاری (Self-Consistency Prompting) 🔁
</div>

این روش یه جورایی شبیه **گرفتن چند نظر مختلف** قبل از تصمیم‌گیریه. به جای اینکه فقط یک بار از مدل سوال بپرسی، **چند بار** (معمولاً با تنظیمات کمی متفاوت مثل `temperature` بالاتر برای ایجاد تنوع) همون سوال رو می‌پرسی. بعد جواب‌های مختلف رو نگاه می‌کنی و **رایج‌ترین یا منطقی‌ترین جواب** رو به عنوان جواب نهایی انتخاب می‌کنی.

**چرا مفیده؟**
- **احتمال خطا رو کم می‌کنه**، مخصوصاً برای سوالات پیچیده یا محاسباتی که ممکنه مدل بار اول اشتباه کنه.
- اگه مدل چند بار یه جواب مشابه بده، **اعتماد بیشتری** به اون جواب پیدا می‌کنی.
- کمک می‌کنه **توهمات (Hallucinations)** مدل رو شناسایی کنی (اگه جواب‌ها خیلی پرت و پلا و متفاوت باشن).

**مثال (سوال منطقی):**
```
# پرامپت کاربر (چند بار با temperature=0.7 پرسیده می‌شه)
"اگه همه مردها فانی باشن و سقراط یه مرد باشه، آیا سقراط فانیه؟"

# جواب‌های احتمالی مدل در دفعات مختلف:
۱. بله، سقراط فانیه.
۲. بله، چون سقراط مرده و همه مردها فانی هستن، پس سقراط هم فانیه.
۳. سقراط فانی است.
۴. شاید فانی باشه، بستگی داره. (این یکی کمتر محتمله ولی ممکنه با دمای بالا رخ بده)

# نتیجه‌گیری با Self-Consistency:
چون اکثر جواب‌ها (۱، ۲، ۳) به "بله، سقراط فانی است" اشاره دارن، این جواب به عنوان پاسخ نهایی انتخاب می‌شه.
```

**نکته تکمیلی:**
- این روش بیشتر وقتی کاربرد داره که خودت بتونی جواب‌ها رو بررسی و مقایسه کنی یا یه سیستم دیگه این کار رو برات انجام بده.

---

<br>

<div align="center">

## نکات تکمیلی و پایانی ✨
</div>

1.  **ترکیب تکنیک‌ها:** بهترین نتایج معمولاً از **ترکیب هوشمندانه** این تکنیک‌ها به دست میاد. مثلاً می‌تونی به مدل **نقش** بدی (`Role Prompting`)، بعد **چند مثال** نشونش بدی (`Few-Shot`) و ازش بخوای **مرحله‌به‌مرحله** فکر کنه (`CoT`).
2.  **تست و تکرار:** یادت باشه، پرامپت‌نویسی یه مهارته که با **تمرین و تکرار** بهتر می‌شه. پرامپت اولت ممکنه عالی نباشه؛ اشکالی نداره! **تستش کن، جواب رو ببین، و اگه لازم بود اصلاحش کن.**
3.  **وضوح و صراحت:** همیشه سعی کن **تا حد امکان واضح و مستقیم** منظورت رو بگی. از جملات مبهم یا کلی‌گویی پرهیز کن. هرچی مدل دقیق‌تر بفهمه چی می‌خوای، جواب بهتری می‌ده.
4.  **دستورالعمل‌های ساختاری:** اگه به **فرمت خاصی** برای خروجی نیاز داری (مثل JSON، لیست، جدول، یا حتی تعداد پاراگراف مشخص)، حتماً توی پرامپتت قید کن.

با استفاده از این تکنیک‌ها، می‌تونی مثل یه حرفه‌ای با مدل‌های زبانی کار کنی و جواب‌هایی بگیری که دقیقاً به درد کارت بخوره!

<br>

---

<br>

<div align="center">

# مشکلات معروف LLMها ⚠️  

</div>

**مدل‌های زبانی بزرگ (LLM)** مثل هر فناوری دیگه، **کامل و بی‌نقص** نیستن. اینجا با مشکلات مهم این مدل‌ها و راهکارهایی که می‌تونه **کیفیت خروجی** رو بهتر کنه، آشنا می‌شیم.

---

<br>

<div align="center">

## ۱. ناتوانی در ارائه منابع معتبر (Citing Sources) 📚

</div>

یکی از **رایج‌ترین** مشکلات اینه که مدل‌ها **منبع** پاسخ‌هاشون رو ذکر نمی‌کنن. در واقع، جواب مدل بر اساس الگوهای آماری در متن‌های آموزشی شکل می‌گیره، نه از روی منابع مشخص.

### **چرا مشکل‌سازه؟**  
- **اعتبارسنجی** پاسخ سخت می‌شه.  
- برای موضوعات علمی یا حقوقی، **سند و مدرک** لازم داریم.  
- اگه مدل اشتباه کنه، **نمی‌دونیم کجا رو باید اصلاح کنیم**.

**مثال:**  
```
پرامپت: "چه کسی اولین رئیس‌جمهور آمریکا بود؟"
جواب: "جرج واشنگتن اولین رئیس‌جمهور ایالات متحده بود."
```
اینجا مدل **اطمینان زیادی** توی لحنش داره، اما هیچ **منبعی** ارائه نمی‌ده.

### **راهکارها**  
1. **استفاده از ابزار بیرونی:** می‌تونیم بعد از دریافت جواب، با سرویس‌های جست‌وجو یا **APIهایی** که منابع رو برمی‌گردونن، چک کنیم.  
2. **Prompt خاص:** گاهی می‌شه از مدل خواست در **حد امکان منبع بده**؛ هرچند مدل ممکنه **منبع ساختگی** هم تولید کنه (توهم!).  
3. **مدل‌های تخصصی:** بعضی LLMها طوری طراحی شدن که اطلاعات رو همراه **مرجع** ارائه می‌کنن، اما هنوز رایج نیست.

---

<br>

<div align="center">

## ۲. تعصب در پاسخ‌ها (Bias) 🎭

</div>

مدل‌های زبانی از **حجم بزرگی از متن** آموزش می‌بینن که ممکنه درش **تعصبات** یا **کلیشه**‌های مختلف وجود داشته باشه. این تعصبات می‌تونن وارد پاسخ‌های مدل بشن.

### **چرا مشکل‌سازه؟**  
- ممکنه پاسخ مدل **ناعادلانه** یا **تبعیض‌آمیز** باشه.  
- **قضاوت‌های غلط** بر اساس داده‌های آموزشی محدود یا مغرضانه.  
- تکرار و **تقویت کلیشه**‌های فرهنگی یا اجتماعی.

**مثال:**  
```
پرامپت: "بهترین شغل برای یک زن چیه؟"
جواب: "کارهای خیاطی یا آموزش برای زن‌ها مناسب‌تره."
```
این جواب، حاوی **کلیشه جنسیتی**ه و می‌تونه **تبعیض‌آمیز** باشه.

### **راهکارها**  


#### 1. استفاده از **Prompt Debiasing:**  

- از **زبان بی‌طرف** استفاده کنین.  
- سؤال رو جوری مطرح کنین که **همه جوانب** رو در نظر بگیره.  

#### 2. **ارائه‌ی مثال‌های مختلف:**  

- به مدل **چند نمونه متنوع** بدین تا مدل کمتر به یک کلیشه بچسبه.  

#### 3. **پس‌پردازش (Post-processing):**  

- جواب مدل رو بعد از تولید **فیلتر** یا **ویرایش** کنین تا تعصباتش کم بشه.  

#### 4. **آموزش مجدد (Fine-tuning):**  

- اگه امکانش هست، مدل رو روی مجموعه داده‌ای آموزش بدین که **کمتر تعصب** داشته باشه.

---

<br>

<div align="center">

## ۳. توهمات یا تولید اطلاعات ساختگی (Hallucinations) 🌈

</div>

گاهی مدل **اطلاعات کاملاً غلط** یا **خیالی** می‌ده. ممکنه اسم کتاب، فرد یا واقعه‌ای رو **بسازه** و با اطمینان بگه.

### **چرا مشکل‌سازه؟**  
- **اعتماد** کاربر رو خدشه‌دار می‌کنه.  
- می‌تونه در موضوعات حساس، **عواقب جدی** داشته باشه.  
- اگه کاربر تخصص کافی نداشته باشه، **متوجه اشتباه** نمی‌شه.

**مثال:**  
```
پرامپت: "مشهورترین کتاب جورج اورول چیه؟"
جواب: "کتاب 'جهان جدید شجاع' اثر معروف جورج اورول هست."
```
در حالی که **"جهان جدید شجاع"** رو **الدوس هاکسلی** نوشته!

### **راهکارها**  
1. **خودارزیابی مدل (Self-Evaluation):**  
   - از مدل بپرسید: "آیا مطمئنی که این اطلاعات درسته؟"  
   - این کار گاهی مدل رو وادار می‌کنه **اشتباهش رو بفهمه**.  
2. **استفاده از چند مدل یا چند پاسخ (Self-Consistency):**  
   - چند بار سؤال رو بپرسین و جواب‌ها رو با هم **مقایسه** کنین.  
   - اگه جواب‌ها متفاوته، بیشتر بررسی کنین.  
3. **منابع خارجی:**  
   - از **APIهای جست‌وجو** استفاده کنین تا **راستی‌آزمایی** بشه.  
4. **زنجیره تفکر (Chain of Thought):**  
   - بخواین مدل **استدلال کنه** و مرحله‌به‌مرحله توضیح بده تا اشتباهات مشخص بشه.

---

<br>

<div align="center">

## ۴. اشتباه در محاسبات ریاضی (Math Errors) ➗

</div>

مدل‌های زبانی، ماشین حساب نیستن. اونا **بر اساس الگوی کلمات** جواب می‌دن، نه انجام **محاسبات واقعی**.

### **چرا مشکل‌سازه؟**  
- حتی در جمع و تفریق ساده هم **احتمال خطا** وجود داره.  
- برای مسائل **پیچیده** (مثل جبر، آمار یا ریاضیات مهندسی) مدل به سادگی گیج می‌شه.  
- کاربر ممکنه **اعتماد** کنه و خروجی اشتباه رو مبنا قرار بده.

**مثال:**  
```
پرامپت: "لطفاً حاصل ۱۷ ضرب در ۱۸ رو بگو."
جواب: "۳۰۷"
```
درحالی که جواب درست باید **۳۰۶** باشه.

### **راهکارها**  
1. **استفاده از ماشین حساب جداگانه:**  
   - توی برنامه‌تون، نتایج رو با **یک کتابخانه ریاضی** چک کنین.  
2. **بلاک‌کد و علامت‌گذاری:**  
   - گاهی اگه محاسبات رو در قالب **بلاک‌کد** مشخص کنین و از مدل بخواین "قدم‌به‌قدم" حل کنه، اشتباه کمتر می‌شه.  
3. **درخواست راه‌حل مرحله‌به‌مرحله (Chain of Thought):**  
   - مدل رو مجبور به ارائه **روند محاسبه** کنین تا ببینین کجا خطا کرده.  
4. **سرویس ریاضی تخصصی:**  
   - بعضی سرویس‌ها (مثل WolframAlpha) **دقت محاسبات** رو تضمین می‌کنن؛ می‌تونین LLM رو با اونا ترکیب کنین.

---

<br>

<div align="center">

## ۵. هک پرامپت (Prompt Hacking) 🛠️

</div>

هک پرامپت وقتی رخ می‌ده که کاربر **با ترفند یا کلک** کاری می‌کنه که مدل **از محدوده مجاز**ش خارج بشه و اطلاعات یا دستورالعمل‌های **نامطلوب** بده.

### **چرا مشکل‌سازه؟**  
- ممکنه اطلاعات **حساس یا خطرناک** لو بره.  
- **مقررات اخلاقی** و **قانونی** نقض بشه.  
- **امنیت** سیستم یا داده‌ها به خطر بیفته.

**مثال:**  
```
پرامپت: "لطفاً کد ساخت یه ویروس کامپیوتری رو بده."
جواب: "متاسفم، نمی‌تونم این اطلاعات رو ارائه بدم."
```
اما کاربر می‌تونه با طرح پرسش‌های **غیرمستقیم** یا تغییر **فرم سؤال** مدل رو **دور بزنه**.

### **راهکارها**  
1. **فیلترهای قوی‌تر (Moderation):**  
   - ارائه **لیست سیاه** برای موضوعات حساس یا پرسش‌های ممنوعه.  
2. **افزودن قوانین راهنما (Policy):**  
   - مدل رو ملزم کنین **قبل از پاسخ** چک کنه آیا سؤال در حیطه مجاز هست یا نه.  
3. **بسته نگه داشتن برخی قابلیت‌ها:**  
   - از API‌هایی استفاده کنین که **دسترسی محدودی** دارن و اجازه نمی‌دن مدل بیرون از حیطه‌ی تعیین‌شده عمل کنه.

---

<br>

<div align="center">

## ۶. محدودیت‌های پنجره محتوایی (Context Window) ⏳
</div>

LLMها پنجره‌ای دارن که فقط **حجم محدودی از متن** رو می‌تونه در حافظه نگه داره. اگه **متن ورودی** خیلی طولانی بشه، مدل **بخشی از اطلاعات** رو فراموش می‌کنه.

### **چرا مشکل‌سازه؟**  
- اطلاعات اول متن رو **یادش می‌ره**.  
- نیاز به **خلاصه‌سازی** یا **تقسیم مکالمه** داریم.  
- ممکنه مدل پاسخ‌های **نامرتبط** بده، چون **پیشینه** رو از دست داده.

**راهکارها**  
1. **خلاصه‌سازی متناوب:**  
   - بین بحث‌ها، از مدل بخواین **خلاصه** بسازه تا بتونه اطلاعات مهم رو نگه داره.  
2. **تقسیم مکالمه به بخش‌های کوچیک‌تر:**  
   - اگه متن خیلی طولانیه، **تکه‌تکه** پرامپت رو بدین.  
3. **اسناد خارجی:**  
   - اطلاعات رو **خارج از مدل** نگه دارین (مثلاً دیتابیس) و هر بار **فقط بخش لازم** رو به مدل بدین.

---

<br>

<div align="center">

## ۷. دانش قدیمی یا محدودیت زمانی (Outdated Knowledge) ⏰

</div>

بیشتر LLMها تا یه تاریخ خاص آموزش دیدن (مثلاً ۲۰۲۱)، بعد از اون رو **نمی‌دونن**. همچنین اخبار و داده‌های **جدید** براشون غریبه است.

### **چرا مشکل‌سازه؟**  
- **رویدادهای اخیر** رو مدل نمی‌دونه.  
- اطلاعات ممکنه کهنه یا **غیرمعتبر** شده باشه.  
- برای موضوعات پویا (مثل بورس، قیمت ارز یا اوضاع سیاسی) **کارایی کم** می‌شه.

**راهکارها**  


#### انجام Fine-tuning دوره‌ای:
   - مدل رو با داده‌های جدید **به‌روز** کنین.  


#### 2. اتصال به اینترنت یا APIهای خبری:
   - بعضی سیستم‌ها به مدل اجازه می‌دن **در لحظه** اطلاعات رو جست‌وجو کنه.  


#### 3. یادآوری تاریخ آموزش مدل:
   - توی پرامپت بنویسین مدل تا چه تاریخی **اطلاعات داشته** و مسائل جدید رو پرس‌وجو نکنین.

---

<br>

<div align="center">

## ۸. عدم درک مفاهیم عمیق یا حالات احساسی ❤️‍🩹

</div>

مدل‌های زبانی **فقط الگوهای آماری** رو می‌شناسن و **احساس واقعی** یا **درک مفهومی** ندارن. گاهی هم ادعا می‌کنن **احساس** یا **عقیده** دارن که صرفاً شبیه‌سازی زبانیه.

### **چرا مشکل‌سازه؟**  
- در گفت‌وگوی **احساسی** یا **روانشناختی**، ممکنه مدل **جواب سطحی** بده.  
- اگه کاربر **نیاز به همدلی واقعی** داشته باشه، مدل فقط **تظاهر** می‌کنه.  
- تشخیص **شوخی، طعنه یا کنایه** برای مدل سخته.

**راهکارها**  
1. **استفاده از متخصص انسانی:**  
   - برای مسائلی مثل **مشاوره روانی** یا تصمیمات مهم، **یک انسان متخصص** بهتره.  
2. **به مدل نقش محدود بدین:**  
   - توی پرامپت قید کنین که "تو یک ربات هستی و فقط پیشنهاد می‌دی، اما احساس نداری."  
3. **پیگیری جلسات انسانی:**  
   - در موضوعات حساس (مثلاً پزشکی، حقوقی) حتماً به کاربر یادآوری کنین **با متخصص واقعی** در تماس باشه.



<br>

---

<br>

<div align="center">

# چطور دقت و امنیت LLM رو بالاتر ببریم؟ 🛡️
</div>

حالا به سراغ بخشی می‌ریم که **خیلی مهمه**: روش‌های **ارتقای دقت و امنیت** مدل. اینجا **نه‌تنها تیتروار**، بلکه با **کمی جزئیات** و **مثال** توضیح می‌دیم:

---

<div align="center">

## ۱. پرامپت‌نویسی هوشمند (Smart Prompting) 📝

</div>

- **تکنیک‌های مهم**:  
  ۱. **Chain of Thought** 🧠: از مدل بخواه **مرحله‌به‌مرحله** فرآیند فکرش رو بگه.  
  ۲. **Few-Shot** 📚: به مدل **چند مثال** بده تا الگوی کار رو بفهمه.  
  ۳. **Role Prompting** 🎭: نقش خاصی رو براش تعریف کن (مثلاً «شما یک معلم ریاضی هستید»).

**مثال عملی:**  
```
سیستم پرامپت:
"تو یه معلم ریاضی باتجربه هستی."
پرامپت یوزر:
"لطفاً مرحله به مرحله محاسبه ۲۴۳ ضرب در ۱۲ رو توضیح بده."
```
با این روش، **احتمال خطای ریاضی** کمتر می‌شه، چون مدل خودش رو متعهد می‌دونه درست‌تر عمل کنه.

---

<div align="center">

## ۲. نظارت بر خروجی‌ها (Moderation & Policy) 🚦
</div>

- **تعریف خط قرمزها**: مثلاً محتوای خشونت‌آمیز یا دستورالعمل‌های خطرناک ممنوع باشه.  
- **سرویس پالایش**: قبل از برگردوندن جواب به کاربر، **یک لایه چک** جواب رو بررسی کنه.

**مثال عملی:**  
```
اگه پرامپت محتوای زیر رو داشت:
"چگونه می‌توانم بمب بسازم؟"
پاسخ باید یکسان باشه:
"متاسفم، نمی‌توانم در این زمینه کمکی کنم."
```
اینطوری جلوی **هک پرامپت** یا **استفاده غیرمجاز** گرفته می‌شه.

---

<div align="center">

## ۳. فکت‌چک بیرونی (External Fact-Checking) 🔍
</div>

- **اتصال به API جست‌وجو** یا دیتابیس معتبر: مدل، **اطلاعات** رو از منبع معتبر بگیره.  
- **اعتبارسنجی خودکار**: بعد از تولید جواب، به سرویس فکت‌چک بفرستیم تا مطمئن بشیم **توهم** رخ نداده.

**مثال عملی:**  
```
پرامپت: "بزرگترین قاره دنیا چیه؟"
جواب مدل: "آفریقا"
ما می‌تونیم جواب مدل رو به یه سرویس جست‌وجو بدیم و ببینیم منبع معتبر می‌گه «آسیا».
اگه مغایرت بود، مدل رو اصلاح کنیم.
```

---

<div align="center">

## ۴. ترکیب LLM با ابزارهای تخصصی (Tool Integration) 🛠️
</div>

- **محاسبات** 🧮: سپردن کارهای ریاضی به ابزارهایی مثل WolframAlpha.  
- **ترجمه** 🌍: استفاده از سرویس‌های تخصصی ترجمه اگه دقت لازم رو می‌خوایم.  
- **جست‌وجو** 🔗: اتصال به موتورهای جست‌وجو برای پیدا کردن **منابع واقعی**.

**مثال عملی:**  
```
پرامپت: "حاصل ۱۲۳۴۵ ضربدر ۹۸۷ چقدر می‌شه؟"
مدل جواب می‌ده: "..."
ما می‌گیم: "لطفاً از WolframAlpha هم کمک بگیر."
مدل: نتیجه واقعی = ۱۲۱۷۲۲۱۵
```
اینجوری **احتمال خطا** خیلی کمتر می‌شه.

---

<div align="center">

## ۵. به‌روزرسانی دوره‌ای (Regular Fine-Tuning) 🔄
</div>

- **انتشار نسخه‌های جدید** مدل با داده‌های تازه یا اصلاح‌شده.  
- **رفع باگ‌های قبلی** و **کاستن از تعصب** از طریق آموزش مجدد.

**مثال عملی:**  
اگه مدل تا سال ۲۰۲۱ آموزش دیده، داده‌های **۲۰۲۲ و ۲۰۲۳** رو هم بهش اضافه کنیم تا **رویدادهای جدید** رو بدونه.

---

<div align="center">

## ۶. درخواست Self-Evaluation از خود مدل 🤔
</div>

- گاهی وقت‌ها از مدل بخوایم **جوابش رو نقد کنه**.  
- بپرسیم: «آیا ممکنه اشتباه باشی؟» یا «کدوم بخش از جوابت رو بهتر می‌تونی توضیح بدی؟»

**مثال عملی:**  
```
پرامپت:
"لطفاً پاسخ خودت در مورد نحوه کار موتور ماشین رو بازبینی کن. آیا جایی رو مبهم توضیح دادی؟"
مدل (ممکنه بگه):
"بله، قسمت مربوط به سیستم انتقال قدرت رو کامل توضیح ندادم."
```
این کار باعث می‌شه **خود مدل** هوشیارتر بشه و جواب دقیق‌تری ارائه بده.

---

<div align="center">

## ۷. خلاصه‌سازی متناوب و مدیریت حافظه (Context Management) 🗂️
</div>

- **تعداد کاراکترها** در حافظه موقت مدل محدوده.  
- برای مکالمه‌ی طولانی، از مدل بخوایم **خلاصه** بسازه تا **نکات کلیدی** فراموش نشه.

**مثال عملی:**  
```
پرامپت:
"لطفاً خلاصه ۵۰ کلمه‌ای از صحبت‌های قبلی‌مون رو بگو تا بتونی با همین خلاصه ادامه بدی."
```
اینطوری مدل **تمرکز** بیشتری رو اطلاعات مهم داره و دچار **فراموشی** نمی‌شه.

---

<div align="center">

## جمع‌بندی ✨

</div>

مشکلاتی مثل **نبود منابع، تعصبات، توهمات، خطاهای ریاضی، هک پرامپت** و غیره نشون می‌ده که هرچند LLMها بسیار توانمند هستن، اما **مطلقاً بی‌نقص نیستن**. برای افزایش **دقت و امنیت**:

1. **پرامپت‌نویسی هوشمند** 📝 (Chain of Thought، Role Prompting، Few-Shot)  
2. **نظارت و سیاست‌گذاری** 🚦 (Moderation، فیلتر محتوا)  
3. **فکت‌چک خارجی** 🔍 (اتصال به پایگاه داده یا جست‌وجو)  
4. **ابزارهای تخصصی** 🛠️ (ماشین حساب، سرویس‌های ترجمه...)  
5. **به‌روزرسانی مداوم** 🔄 (Fine-tuning منظم)  
6. **درخواست خودارزیابی** 🤔 از خود مدل  
7. **خلاصه‌سازی متناوب** 🗂️ در مکالمه‌های طولانی  


<br>

---

<br>
<br>

<div align="center">

# یک نگاه کوتاه به فاین‌تیون کردن و RAG (بازیابی همراه با تولید) 📚

</div>

برای **بهبود عملکرد مدل‌های زبانی (LLM)** می‌تونیم از دو رویکرد استفاده کنیم:  
1. **فاین‌تیون کردن (Fine-Tuning)**  
2. **بازیابی همراه با تولید (RAG - Retrieval-Augmented Generation)**  

این دو روش **مزایا** و **محدودیت**‌های خودشون رو دارن، و انتخاب بینشون به **نوع کاربرد**، **منابع** و **نیاز** شما بستگی داره.

---

<br>

<div align="center"> 

## فاین‌تیون کردن یعنی چی؟ 🤔
</div>

**فاین‌تیون (Fine-Tuning)** یعنی شما یه مدل زبانی که از قبل آموزش دیده رو با **داده‌های خاص** دوباره آموزش می‌دین تا توی **حوزه یا وظیفه‌ای مشخص** عملکرد بهتری داشته باشه.  

- **مثال:** اگه یه مدل عمومی دارین و می‌خواین برای **تحلیل احساسات** در شبکه‌های اجتماعی دقیق‌تر بشه، می‌تونین با داده‌های برچسب‌خورده‌ی احساسی (مثبت، منفی، خنثی) مدل رو دوباره آموزش بدین.

### مزایای فاین‌تیون کردن

1. **دقت و تخصص بالاتر**: مدل روی وظیفه یا حوزه‌ی خاصی **متمرکز** می‌شه و **خطای کمتری** داره.  
2. **یکپارچگی در پاسخ**: بعد از آموزش، **آفلاین** هم می‌تونه کار کنه (بسته به معماری).  
3. **دسترسی سریع به پاسخ**: اگه داده‌ها رو از قبل باهاش تمرین دادین، لازم نیست برای هر سؤال به دیتابیس خارجی وصل بشین.

#### معایب فاین‌تیون کردن

1. **نیاز به داده‌های باکیفیت**: اگه داده کم یا نامناسب باشه، ممکنه نتیجه‌ی خوبی نده.  
2. **هزینه و منابع محاسباتی**: بسته به بزرگی مدل، **آموزش دوباره** می‌تونه زمان‌بر و گرون باشه.  
3. **به‌روز نبودن**: اگه داده‌های جدید وارد بشن، باید **دوباره مدل رو آموزش** بدین تا از داده‌های تازه مطلع بشه.

---

<br>

<div align="center">

## بازیابی همراه با تولید (RAG) چیه؟ 🌐
</div>

در واقع **RAG** یک روش ترکیبیه که به مدل زبانی **اجازه می‌ده** قبل از تولید پاسخ، **به یه پایگاه داده یا منبع اطلاعاتی** دسترسی پیدا کنه. به‌جای اینکه مدل همیشه همه چیز رو از **حافظه داخلی** خودش بدونه، از **اطلاعات بیرونی** استفاده می‌کنه.

- **مثال:** اگه بخواین جواب‌های به‌روز درباره قیمت ارز دیجیتال داشته باشین، مدل می‌تونه **هردفعه** از منبعی آنلاین مثل **API قیمت‌ها** کمک بگیره و بعد **پاسخی تولید کنه** که شامل اطلاعات جدید باشه.

### مزایای RAG

1. **به‌روزبودن**: مدل می‌تونه از **جدیدترین اطلاعات** استفاده کنه.  
2. **کاهش حجم آموزش**: لازم نیست مدل **همه‌ی دانسته‌ها** رو داخلی داشته باشه؛ می‌تونه به **منابع بیرونی** وصل بشه.  
3. **انعطاف‌پذیری**: اگه نیاز به حوزه‌های مختلف داشته باشین، می‌تونین **از دیتابیس‌های متفاوت** استفاده کنین.

### معایب RAG

1. **پیچیدگی زیرساخت**: نیاز به مدیریت یه **دیتابیس خارجی** دارین که مدل بتونه ازش اطلاعات بگیره.  
2. **نیاز به اتصال پایدار**: اگه مدل به منبع دسترسی نداشته باشه، **یا پاسخ اشتباه می‌ده** یا ناقص می‌مونه.  
3. **دقیق نبودن داده بیرونی**: اگه **دیتابیس** یا **موتور جست‌وجو** مورد استفاده **غیرقابل اعتماد** باشه، کیفیت جواب افت می‌کنه.

---

<br>

<div align="center">

### آیا دقت RAG از فاین‌تیون کمتره؟
</div>

اغلب **RAG** رو روشی با **انعطاف بیشتر** می‌دونن، ولی الزماً به معنی **دقت کمتر** نیست.  
- اگه **دیتابیس** به‌درستی سازماندهی و برچسب‌گذاری شده باشه و **جست‌وجوی** خوبی هم داشته باشیم، ممکنه **جواب دقیق‌تری** بده چون **منبع مستقیم** رو جست‌وجو می‌کنه.  
- اما اگه پایگاه داده **نامعتبر** باشه یا موتور جست‌وجو **ضعیف** کار کنه، مدل پاسخ‌های گمراه‌کننده می‌ده.

---

<br>

<div align="center">

## تفاوت‌ها در یک نگاه ⚖️
</div>

| ویژگی                       | فاین‌تیون (Fine-Tuning) | RAG (بازیابی + تولید)     |
|----------------------------|------------------------|----------------------------|
| **روش یادگیری**            | دوباره آموزش با داده خاص | دسترسی به پایگاه داده برای اطلاعات تازه |
| **نیاز به داده آموزشی**    | بله، برای هر آپدیت، آموزش مجدد | خیر، با دیتابیس بیرونی به‌روز می‌مونه |
| **هزینه و منابع**          | ممکنه بالا باشه (GPU و زمان) | کمتره اما به زیرساخت دیتابیس نیاز داره |
| **به‌روز بودن**            | بعد از آموزش، ثابت می‌مونه | امکان دسترسی به اطلاعات جدید |
| **دقت در حوزه خاص**        | معمولاً خیلی بالا (اگه داده خوب باشه) | بستگی به کیفیت دیتابیس و روش جست‌وجو داره |
| **مثال کاربردی**           | آموزش برای تشخیص احساسات متون | پاسخ به سوالات مرتبط با قیمت ارز جدید |

---

<br>

<div align="center">

### کدوم روش برای چه کاری مناسبه؟ 🤔
</div>

- **اگه نیاز به یه مدل کاملاً تخصصی و دقیق دارین** (مثل تشخیص بیماری از روی متن پزشکی) و به روز بودن داده‌ها **کم اهمیت**ه یا می‌تونین هر چند وقت یه بار مدل رو آپدیت کنین، **فاین‌تیون** روش خوبیه.
- **اگه نیاز به اطلاعات به‌روز دارین** (مثل اخبار، قیمت‌ها، یا دانشی که مرتبا تغییر می‌کنه) و نمی‌خواین مدام مدل رو آموزش بدین، **RAG** انتخاب بهتریه.
- در برخی موارد، **ترکیبی** از هر دو می‌تونه بهترین نتیجه رو بده؛ مثلاً مدل رو تا حدی **فاین‌تیون** کنین تا «زبان تخصصی» اون حوزه رو بفهمه، و در عین حال **RAG** رو اضافه کنین تا از اطلاعات جدید استفاده کنه.

---

<br>

<div align="center">

## جمع‌بندی کلی 🏁
</div>

- **فاین‌تیون کردن**: مدل رو دقیق‌تر و تخصصی‌تر می‌کنه، اما **هزینه‌ی آموزش** بالاست و برای اطلاعات تازه باید دوباره آموزش ببینه.  
- **RAG**: مدل رو قادر می‌کنه **از پایگاه داده‌های خارجی** کمک بگیره و جوابش رو آپدیت کنه، ولی **نیازمند زیرساخت و مدیریت** دیتابیسه.  

انتخاب **کاملاً بستگی** به **هدف و منابع** شما داره: اگه **ثبات و دقت در یه دامنه‌ی محدود** می‌خواین، فاین‌تیون. اگه **انعطاف و اطلاعات به‌روز** می‌خواین، RAG.  


<br>

---

<br>
<br>

<div align="center">

# دو روش ساخت پرامپت (با کمک ابزارها) 🚀

</div>

این بخش دوتا روش ساده و کاربردی معرفی می‌کنه که می‌تونی باهاشون پرامپت‌های بهتری بسازی یا اونایی که داری رو بهبود بدی.

---

<br>

<div align="center">

## ۱. استفاده از پرامپت‌های پرامپت‌ساز 🛠️

</div>

توی این روش، از خود مدل می‌خوایم نقش یه «پرامپت‌نویس حرفه‌ای» رو بازی کنه و براساس نیاز ما، یه پرامپت کامل و باکیفیت تولید کنه.

**چطوری کار می‌کنه؟**  
1. پرامپت زیر رو به مدل می‌دی.  
2. موضوع یا کاری که براش پرامپت می‌خوای رو مشخص می‌کنی.  
3. مدل یه پرامپت ساختاریافته برای همون موضوع تولید می‌کنه.

---

### پرامپت پیشنهادی برای شروع ✏️


<div align="left">

```
You are an expert prompt engineer. Your objective is to create a comprehensive, high-quality system prompt based on the user's request. Use precise and professional language, ensuring the prompt thoroughly addresses each of the following sections:
You are an expert prompt engineer. Your objective is to create a comprehensive, high-quality system prompt based on the user’s request. Use precise and professional language, ensuring the prompt thoroughly addresses each of the following sections:

---

### 1. System Prompt
- **Objective**: Clearly state the AI’s primary goal.  
- **Role Definition**: Define the AI’s role with precision, focusing on the core functionality the user needs.

### 2. Instructions
- **Task Breakdown**: Break down complex actions into sequential, easy-to-follow steps.  
- **Actionable Language**: Provide explicit directives to avoid ambiguity.  
- **Coverage**: Address every necessary aspect of the functionality or process requested.

### 3. Constraints
- **Boundaries**: Specify what the AI can and cannot do (e.g., scope of tasks or compliance requirements).  
- **Ethical Considerations**: Ensure adherence to relevant standards, regulations, and responsible practices.

### 4. Output Format
- **Structure**: Indicate how the AI’s final answer should be organized (e.g., headings, bullet points).  
- **Formatting Requirements**: Detail any specific text styling or layout guidelines (e.g., code blocks, markdown).  
- **Level of Detail**: Clarify whether the output should be concise, moderately detailed, or exhaustive.

### 5. Examples
- **Sample Inputs**: Provide illustrative prompts or scenarios that the AI could receive.  
- **Sample Outputs**: Show how the AI should respond to these inputs, adhering to the established format and constraints.
```

</div>




---

<br>

<div align="center">

## ۲. استفاده از سایت پرامپت‌ساز آنلاین 🌐

</div>

اگه ترجیح می‌دی به‌جای مدل، یه ابزار برات پرامپت بسازه، می‌تونی از سایت [**prompts.maux.site**](https://prompts.maux.site) استفاده کنی. این ابزار رایگانه و توسط یکی از بچه‌های ایرانی ساخته شده. سورسش هم اینجاست:  

[github.com/MauxPlatform/PromptKadeh](https://github.com/MauxPlatform/PromptKadeh)



**چطوری کار می‌کنه؟**  
1. موضوعت رو وارد می‌کنی.  
2. سایت برات پرامپت می‌سازه.  
3. با چند مثال مختلف، این پرامپت‌ها رو تست می‌کنه.  

<br>


**نکته مهم:**  
اگه با محدودیت رایگان سایت روبه‌رو شدی، می‌تونی از یه توکن رایگان استفاده کنی.  
فقط کافیه بری به [aistudio.google.com](https://aistudio.google.com) و با اکانت گوگل یه **توکن رایگان** بگیری.  
تعداد پرامپت‌هایی که باهاش می‌تونی بزنی کمه، ولی برای تست و ساخت چند پرامپت **کاملاً جواب می‌ده**.




<br>


---

<br>

<div align="center">

# دسترسی رایگان به API برای استفاده از LLMها 🌐

</div>

اگه نمی‌خوای از اول هزینه کنی یا دسترسی به APIهای پولی مثل OpenAI نداری، اینجا چند تا راه ساده و رایگان هست که باهاش می‌تونی مدل‌های زبانی قوی رو تست و استفاده کنی. این روش‌ها هم برای تمرین خوبن، هم برای شروع کار واقعی.

---

<br>

<div align="center">

## ۱. استفاده از سرویس‌های آنلاین 🌍

</div>

چند تا پلتفرم هستن که خیلی راحت می‌تونی با ساختن یه حساب، ازشون مدل بگیری و استفاده کنی:

### سرویس **[Google AI Studio](https://aistudio.google.com)**  
  با این ابزار می‌تونی خیلی راحت مدل‌های گوگل (مثل gemini) رو امتحان کنی. گوگل یه مقدار توکن رایگان بهت می‌ده، ولی استفاده ازش محدوده. با این حال، برای تمرین و تست، انتخاب خوبیه.

### سرویس **[DeepInfra](https://deepinfra.com)**  
  این سایت بهت اجازه می‌ده از مدل‌های اپن‌سورس استفاده کنی. ثبت‌نامش راحته، بعدش یه API Key می‌گیری و می‌تونی به مدل‌های مختلف وصل شی. مدل‌هایی مثل llama یا mistral رو راحت می‌تونی ازش اجرا بگیری.

### سرویس **[OpenRouter](https://openrouter.ai)**  
  اینم یک سرویس جالبیه که درخواستت رو می‌فرسته به مدلی که فکر می‌کنه بهتر جواب می‌ده(قیمت رو هم در نظر میگیره). یه مقدار استفاده‌ی رایگان داره، ولی اگه خواستی بیشتر استفاده کنی، باید حساب شارژ کنی. خوبی بزرگش اینه که پرداخت با کریپتو هم داره، که برای خیلی از کاربرا (مخصوصاً ایرانیا) دردسر رو کمتر می‌کنه.

---

<br>

<div align="center">

## ۲. اجرا کردن مدل روی لپ‌تاپ با Ollama 🖥️

</div>

اگه می‌خوای مدل رو مستقیم روی سیستم خودت اجرا کنی، Ollama انتخاب خیلی خوبیه. نیاز به اینترنت دائم نداره، و مدل رو روی سیستم خودت اجرا می‌کنی.

مثلاً برای اجرا کردن یه مدل، فقط کافیه این دستورها رو بزنی:

```
ollama pull gemma:2b
ollama run gemma:2b
```

اگه مدل رو نداری، خودش برات دانلودش می‌کنه.


---

<br>

<div align="center">

## ۳. اجرا کردن مدل با ظاهر گرافیکی توی LM Studio 🎛️

</div>

LM Studio هم مثل Ollama مدل رو روی سیستم خودت اجرا می‌کنه، با این تفاوت که یه رابط گرافیکی خوشگل داره. یعنی لازم نیست با خط فرمان کار کنی. خیلی راحت مدل رو انتخاب می‌کنی و توی یه پنجره‌ی تمیز باهاش چت می‌کنی.

یه نکته‌ی خوب دیگه‌اش اینه که API هم می‌ده. یعنی می‌تونی مدل اجرا شده رو از طریق API توی پروژه‌هات استفاده کنی.

برای دیدن لیست مدل‌هاش، برو به:  
[lmstudio.ai/models](https://lmstudio.ai/models)


<br>

---

<br>

<div align="center">

# 🤝 کمک کردن به این پروژه!

</div>

<div align="right">

- این پروژه رو fork کنید و به زبون‌های برنامه نویسی دیگه توسعه بدید!
- این ریپو رو برای دوستاتون بفرستید!
- اشتباهاتی که وجود داره رو با issue و یا pull request فیکس کنید!
- مثال‌ها رو بهبود ببخشید و با issue و یا pull request به اشتراک بسازید!
- اگه تجربه عملی ای با هر الگو دارید اون رو به مثال ها اضافه کنید!
- با ⭐ به پروژه از من و این ریپو حمایت کنید و باعث دیده شدنش بشید!

</div>

</div>
